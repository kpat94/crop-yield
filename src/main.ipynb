{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7eaa9d44ce82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConcatDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "from torch.utils.data import DataLoader,ConcatDataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "#### Read fertilizer data in the form of nutrients<br>\n",
    "#### Not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63d82f3ec173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFertilizerNutrients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inputs_FertilizersNutrient_E_All_Data_NOFLAG.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFertilizerNutrients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "FertilizerNutrients = pd.read_csv(\"Inputs_FertilizersNutrient_E_All_Data_NOFLAG.csv\", engine='python');\n",
    "FertilizerNutrients.tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pesticides and fertilizer products data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Pesticides \n",
      "\n",
      "***** Fertilizer products \n",
      "\n",
      "***** Production yield \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Area Code                                     Area  Item Code  \\\n",
       "0              2                              Afghanistan        221   \n",
       "1              2                              Afghanistan        221   \n",
       "2              2                              Afghanistan        221   \n",
       "3              2                              Afghanistan        711   \n",
       "4              2                              Afghanistan        711   \n",
       "...          ...                                      ...        ...   \n",
       "50195       5817  Net Food Importing Developing Countries       1729   \n",
       "50196       5817  Net Food Importing Developing Countries       1729   \n",
       "50197       5817  Net Food Importing Developing Countries       1735   \n",
       "50198       5817  Net Food Importing Developing Countries       1735   \n",
       "50199       5817  Net Food Importing Developing Countries       1735   \n",
       "\n",
       "                                   Item  Element Code         Element    Unit  \\\n",
       "0                   Almonds, with shell          5312  Area harvested      ha   \n",
       "1                   Almonds, with shell          5419           Yield   hg/ha   \n",
       "2                   Almonds, with shell          5510      Production  tonnes   \n",
       "3      Anise, badian, fennel, coriander          5312  Area harvested      ha   \n",
       "4      Anise, badian, fennel, coriander          5419           Yield   hg/ha   \n",
       "...                                 ...           ...             ...     ...   \n",
       "50195                   Treenuts, Total          5419           Yield   hg/ha   \n",
       "50196                   Treenuts, Total          5510      Production  tonnes   \n",
       "50197                Vegetables Primary          5312  Area harvested      ha   \n",
       "50198                Vegetables Primary          5419           Yield   hg/ha   \n",
       "50199                Vegetables Primary          5510      Production  tonnes   \n",
       "\n",
       "            Y1961       Y1962       Y1963  ...       Y2009       Y2010  \\\n",
       "0             NaN         NaN         NaN  ...     11029.0     11210.0   \n",
       "1             NaN         NaN         NaN  ...     39154.0     49955.0   \n",
       "2             NaN         NaN         NaN  ...     43183.0     56000.0   \n",
       "3             NaN         NaN         NaN  ...     17748.0     17000.0   \n",
       "4             NaN         NaN         NaN  ...      6203.0      6000.0   \n",
       "...           ...         ...         ...  ...         ...         ...   \n",
       "50195      6118.0      6318.0      6618.0  ...      4728.0      5415.0   \n",
       "50196    255724.0    295318.0    315667.0  ...   1338811.0   1370375.0   \n",
       "50197   1877800.0   1925219.0   1992435.0  ...   6215085.0   6377100.0   \n",
       "50198     66297.0     67612.0     68080.0  ...    115100.0    113551.0   \n",
       "50199  12449173.0  13016875.0  13564405.0  ...  71535441.0  72412363.0   \n",
       "\n",
       "            Y2011       Y2012       Y2013       Y2014       Y2015       Y2016  \\\n",
       "0         13469.0     13490.0     14114.0     13703.0     14676.0     19481.0   \n",
       "1         45000.0     45960.0     29910.0     19996.0     16521.0     16859.0   \n",
       "2         60611.0     62000.0     42215.0     27400.0     24246.0     32843.0   \n",
       "3         19500.0     18500.0     18500.0     30000.0     25000.0     25638.0   \n",
       "4          6414.0      6757.0      6757.0      7167.0      7200.0      7037.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "50195      5429.0      5417.0      5198.0      5177.0      5234.0      5514.0   \n",
       "50196   1619567.0   1662130.0   1772637.0   1835843.0   2090427.0   1953370.0   \n",
       "50197   6423774.0   6456448.0   6578776.0   6792359.0   6989468.0   7030316.0   \n",
       "50198    114497.0    116388.0    115156.0    117847.0    118811.0    117457.0   \n",
       "50199  73550283.0  75145043.0  75758376.0  80046102.0  83042366.0  82575747.0   \n",
       "\n",
       "            Y2017       Y2018  \n",
       "0         19793.0     20053.0  \n",
       "1         13788.0     17161.0  \n",
       "2         27291.0     34413.0  \n",
       "3         27582.0     25785.0  \n",
       "4          6954.0      7036.0  \n",
       "...           ...         ...  \n",
       "50195      5251.0      5461.0  \n",
       "50196   2076194.0   2219089.0  \n",
       "50197   7043245.0   7233314.0  \n",
       "50198    116865.0    117018.0  \n",
       "50199  82311014.0  84643108.0  \n",
       "\n",
       "[50200 rows x 65 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "InputPesiticides = pd.read_csv(\"Inputs_Pesticides_Use_E_All_Data_NOFLAG.csv\", engine='python')\n",
    "print(\"***** Pesticides \\n\")\n",
    "InputPesiticides.head\n",
    "\n",
    "# %%\n",
    "# Read fertilizer data in the form of products\n",
    "FertilizerProducts = pd.read_csv(\"Inputs_FertilizersProduct_E_All_Data_NOFLAG.csv\", engine='python')\n",
    "print(\"***** Fertilizer products \\n\")\n",
    "FertilizerProducts.head\n",
    "# %%\n",
    "\n",
    "# Read the crop yield data\n",
    "ProductionYield = pd.read_csv(\"Production_Crops_E_All_Data_NOFLAG.csv\",engine='python')\n",
    "print(\"***** Production yield \\n\")\n",
    "ProductionYield.head\n",
    "# %%\n",
    "# print(FertilizerNutrients.columns);\n",
    "# #%%\n",
    "# print(FertilizerNutrients['Area'])\n",
    "#%%\n",
    "# Filter out the data for Australia\n",
    "# is_Country_Australia = FertilizerNutrients['Area']==\"Australia\"\n",
    "# Australia_Fertilizers_Nutrients = FertilizerNutrients[is_Country_Australia]\n",
    "# print(Australia_Fertilizers_Nutrients.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "Get the fertilizer usage in terms of agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertilizer products Index(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
      "       'Unit', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007', 'Y2008',\n",
      "       'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2014', 'Y2015', 'Y2016',\n",
      "       'Y2017'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Input pesticides Index(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
      "       'Unit', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996',\n",
      "       'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004',\n",
      "       'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012',\n",
      "       'Y2013', 'Y2014', 'Y2015', 'Y2016', 'Y2017'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# is_Element_Agricultural_Use = Australia_Fertilizers_Nutrients['Element']==\"Agricultural Use\"\n",
    "# Australia_Fertilizers_Nutrients_Agricultural = Australia_Fertilizers_Nutrients[is_Element_Agricultural_Use]\n",
    "# print(Australia_Fertilizers_Nutrients_Agricultural)\n",
    "# %%\n",
    "print(\"Fertilizer products\",FertilizerProducts.columns)\n",
    "print(\"\\n\")\n",
    "print(\"Input pesticides\", InputPesiticides.columns)\n",
    "#%%\n",
    "# Filter out the data for Australia\n",
    "is_Country_Australia_Products = FertilizerProducts['Area']==\"Australia\"\n",
    "Australia_Fertilizers_Products = FertilizerProducts[is_Country_Australia_Products]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_Country_Australia_Pesticides = InputPesiticides['Area']==\"Australia\"\n",
    "Australia_Pesticides = InputPesiticides[is_Country_Australia_Pesticides]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the fertilizer usage for agricultural use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertilizers \n",
      "\n",
      "Index(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
      "       'Unit', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007', 'Y2008',\n",
      "       'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2014', 'Y2015', 'Y2016',\n",
      "       'Y2017'],\n",
      "      dtype='object')\n",
      "602                                   Ammonia, anhydrous\n",
      "607                                Ammonium nitrate (AN)\n",
      "613                                    Ammonium sulphate\n",
      "618    Calcium ammonium nitrate (CAN) and other mixtu...\n",
      "624                           Diammonium phosphate (DAP)\n",
      "634                         Monoammonium phosphate (MAP)\n",
      "639                                      NPK fertilizers\n",
      "644                Other nitrogenous fertilizers, n.e.c.\n",
      "649                                   Other NP compounds\n",
      "654                 Other phosphatic fertilizers, n.e.c.\n",
      "667                                         PK compounds\n",
      "672         Potassium chloride (muriate of potash) (MOP)\n",
      "677                                    Potassium nitrate\n",
      "682        Potassium sulphate (sulphate of potash) (SOP)\n",
      "691                            Superphosphates above 35%\n",
      "695                               Superphosphates, other\n",
      "701                                                 Urea\n",
      "706            Urea and ammonium nitrate solutions (UAN)\n",
      "Name: Item, dtype: object\n",
      "\n",
      "\n",
      "Pesticides \n",
      "\n",
      "Index(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
      "       'Unit', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996',\n",
      "       'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004',\n",
      "       'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012',\n",
      "       'Y2013', 'Y2014', 'Y2015', 'Y2016', 'Y2017'],\n",
      "      dtype='object')\n",
      "160             Pesticides (total)\n",
      "161                   Insecticides\n",
      "162                     Herbicides\n",
      "163    Fungicides and Bactericides\n",
      "164           Other Pesticides nes\n",
      "165           Other Pesticides nes\n",
      "Name: Item, dtype: object\n"
     ]
    }
   ],
   "source": [
    "is_Agricultural = Australia_Fertilizers_Products['Element']==\"Agricultural Use\"\n",
    "Australia_Fertilizers_Products_Agricultural = Australia_Fertilizers_Products[is_Agricultural]\n",
    "print(\"Fertilizers \\n\")\n",
    "print(Australia_Fertilizers_Products_Agricultural.columns)\n",
    "print(Australia_Fertilizers_Products_Agricultural['Item'])\n",
    "print(\"\\n\")\n",
    "print(\"Pesticides \\n\")\n",
    "print(Australia_Pesticides.columns)\n",
    "print(Australia_Pesticides['Item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "7 years for training - 2007 to 2013<br>\n",
    "3 years fro validation - 2014 to 2016<br>\n",
    "2017 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Item  Y2007  Y2008  \\\n",
      "602                                 Ammonia, anhydrous    NaN    NaN   \n",
      "607                              Ammonium nitrate (AN)    NaN    NaN   \n",
      "613                                  Ammonium sulphate    NaN    NaN   \n",
      "618  Calcium ammonium nitrate (CAN) and other mixtu...    NaN    NaN   \n",
      "624                         Diammonium phosphate (DAP)    NaN    NaN   \n",
      "634                       Monoammonium phosphate (MAP)    NaN    NaN   \n",
      "639                                    NPK fertilizers    NaN    NaN   \n",
      "644              Other nitrogenous fertilizers, n.e.c.    NaN    NaN   \n",
      "649                                 Other NP compounds    NaN    NaN   \n",
      "654               Other phosphatic fertilizers, n.e.c.    NaN    NaN   \n",
      "667                                       PK compounds    NaN    NaN   \n",
      "672       Potassium chloride (muriate of potash) (MOP)    NaN    NaN   \n",
      "677                                  Potassium nitrate    NaN    NaN   \n",
      "682      Potassium sulphate (sulphate of potash) (SOP)    NaN    NaN   \n",
      "691                          Superphosphates above 35%    NaN    NaN   \n",
      "695                             Superphosphates, other    NaN    NaN   \n",
      "701                                               Urea    NaN    NaN   \n",
      "706          Urea and ammonium nitrate solutions (UAN)    NaN    NaN   \n",
      "\n",
      "        Y2009      Y2010      Y2011      Y2012      Y2013      Y2014  \\\n",
      "602       NaN        NaN        NaN        NaN        NaN    45524.0   \n",
      "607       NaN        NaN        NaN        NaN        NaN   504150.0   \n",
      "613       NaN   160856.0    47329.0   156799.0   134630.0   138915.0   \n",
      "618      74.0        NaN        NaN        NaN        NaN        NaN   \n",
      "624       NaN  1022315.0        NaN  1124066.0        NaN        NaN   \n",
      "634  416724.0        NaN   713917.0        NaN        NaN   860792.0   \n",
      "639   41037.0  1258690.0   116990.0        NaN        NaN        NaN   \n",
      "644       NaN        NaN        NaN        NaN        NaN   362206.0   \n",
      "649    2208.0    14162.0    42783.0        NaN        NaN        NaN   \n",
      "654       NaN        NaN        NaN        NaN        NaN   349280.0   \n",
      "667     130.0        NaN      609.0        NaN        NaN        NaN   \n",
      "672       NaN        NaN   221515.0        NaN   209601.0   231525.0   \n",
      "677    5786.0    34782.0    12869.0    33525.0        NaN    40976.0   \n",
      "682   21154.0   176501.0    50525.0   128454.0        NaN        NaN   \n",
      "691   78618.0   961962.0    89395.0   899764.0   512404.0   632202.0   \n",
      "695       NaN        NaN        NaN        NaN   124002.0   161001.0   \n",
      "701  740505.0  1057520.0  1485631.0  1157512.0  1092540.0  1753221.0   \n",
      "706  110721.0   231981.0        NaN   273876.0   143709.0   122400.0   \n",
      "\n",
      "         Y2015      Y2016  \n",
      "602    40000.0    39761.0  \n",
      "607   176522.0   165970.0  \n",
      "613   192000.0   172581.0  \n",
      "618        NaN        NaN  \n",
      "624        NaN        NaN  \n",
      "634  1096851.0  1114790.0  \n",
      "639        NaN        NaN  \n",
      "644   304000.0   211449.0  \n",
      "649        NaN        NaN  \n",
      "654   413000.0   261487.0  \n",
      "667        NaN        NaN  \n",
      "672   239836.0   184787.0  \n",
      "677    59000.0    48019.0  \n",
      "682        NaN        NaN  \n",
      "691   752000.0   737519.0  \n",
      "695   198000.0   144503.0  \n",
      "701  1772020.0  1548247.0  \n",
      "706   109400.0   144700.0  \n",
      "Index(['Item', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013',\n",
      "       'Y2014', 'Y2015', 'Y2016'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_ten_years_fertlizers = Australia_Fertilizers_Products_Agricultural.drop(['Area Code', 'Area', 'Item Code', 'Element Code','Element',\n",
    "       'Unit','Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2017'], axis=1)\n",
    "print(X_ten_years_fertlizers)\n",
    "print(X_ten_years_fertlizers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Item     Y2007     Y2008     Y2009     Y2010  \\\n",
      "160           Pesticides (total)  32446.24  42935.38  38065.69  42169.39   \n",
      "161                 Insecticides   7262.97   9610.92   8520.86   9439.46   \n",
      "162                   Herbicides  22403.90  29646.57  26284.08  29117.66   \n",
      "163  Fungicides and Bactericides   2324.91   3076.50   2727.56   3021.61   \n",
      "164         Other Pesticides nes    454.47    601.39    533.18    590.66   \n",
      "165         Other Pesticides nes    454.47    601.39    533.18    590.66   \n",
      "\n",
      "        Y2011     Y2012     Y2013     Y2014     Y2015     Y2016  \n",
      "160  47632.98  48687.88  45177.19  49857.35  50921.60  63416.48  \n",
      "161  10662.47  10898.60  10112.74  11160.38  11398.61  14195.54  \n",
      "162  32890.23  33618.62  31194.52  34426.14  35161.00  43788.62  \n",
      "163   3413.10   3488.69   3237.13   3572.49   3648.74   4544.05  \n",
      "164    667.19    681.97    632.79    698.35    713.25    888.27  \n",
      "165    667.19    681.97    632.79    698.35    713.25    888.27  \n",
      "Index(['Item', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013',\n",
      "       'Y2014', 'Y2015', 'Y2016'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_ten_years_pesticides = Australia_Pesticides.drop(['Area Code', 'Area', 'Item Code', 'Element Code', 'Element',\n",
    "       'Unit', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2017'], axis=1)\n",
    "print(X_ten_years_pesticides)\n",
    "print(X_ten_years_pesticides.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "Drop Ammonia anyhydrous and Ammonia nitrate from 2007 to 2013. It has not been used in these years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Item  Y2007  Y2008  \\\n",
      "613                                  Ammonium sulphate    NaN    NaN   \n",
      "618  Calcium ammonium nitrate (CAN) and other mixtu...    NaN    NaN   \n",
      "624                         Diammonium phosphate (DAP)    NaN    NaN   \n",
      "634                       Monoammonium phosphate (MAP)    NaN    NaN   \n",
      "639                                    NPK fertilizers    NaN    NaN   \n",
      "644              Other nitrogenous fertilizers, n.e.c.    NaN    NaN   \n",
      "649                                 Other NP compounds    NaN    NaN   \n",
      "654               Other phosphatic fertilizers, n.e.c.    NaN    NaN   \n",
      "667                                       PK compounds    NaN    NaN   \n",
      "672       Potassium chloride (muriate of potash) (MOP)    NaN    NaN   \n",
      "677                                  Potassium nitrate    NaN    NaN   \n",
      "682      Potassium sulphate (sulphate of potash) (SOP)    NaN    NaN   \n",
      "691                          Superphosphates above 35%    NaN    NaN   \n",
      "695                             Superphosphates, other    NaN    NaN   \n",
      "701                                               Urea    NaN    NaN   \n",
      "706          Urea and ammonium nitrate solutions (UAN)    NaN    NaN   \n",
      "\n",
      "        Y2009      Y2010      Y2011      Y2012      Y2013      Y2014  \\\n",
      "613       NaN   160856.0    47329.0   156799.0   134630.0   138915.0   \n",
      "618      74.0        NaN        NaN        NaN        NaN        NaN   \n",
      "624       NaN  1022315.0        NaN  1124066.0        NaN        NaN   \n",
      "634  416724.0        NaN   713917.0        NaN        NaN   860792.0   \n",
      "639   41037.0  1258690.0   116990.0        NaN        NaN        NaN   \n",
      "644       NaN        NaN        NaN        NaN        NaN   362206.0   \n",
      "649    2208.0    14162.0    42783.0        NaN        NaN        NaN   \n",
      "654       NaN        NaN        NaN        NaN        NaN   349280.0   \n",
      "667     130.0        NaN      609.0        NaN        NaN        NaN   \n",
      "672       NaN        NaN   221515.0        NaN   209601.0   231525.0   \n",
      "677    5786.0    34782.0    12869.0    33525.0        NaN    40976.0   \n",
      "682   21154.0   176501.0    50525.0   128454.0        NaN        NaN   \n",
      "691   78618.0   961962.0    89395.0   899764.0   512404.0   632202.0   \n",
      "695       NaN        NaN        NaN        NaN   124002.0   161001.0   \n",
      "701  740505.0  1057520.0  1485631.0  1157512.0  1092540.0  1753221.0   \n",
      "706  110721.0   231981.0        NaN   273876.0   143709.0   122400.0   \n",
      "\n",
      "         Y2015      Y2016  \n",
      "613   192000.0   172581.0  \n",
      "618        NaN        NaN  \n",
      "624        NaN        NaN  \n",
      "634  1096851.0  1114790.0  \n",
      "639        NaN        NaN  \n",
      "644   304000.0   211449.0  \n",
      "649        NaN        NaN  \n",
      "654   413000.0   261487.0  \n",
      "667        NaN        NaN  \n",
      "672   239836.0   184787.0  \n",
      "677    59000.0    48019.0  \n",
      "682        NaN        NaN  \n",
      "691   752000.0   737519.0  \n",
      "695   198000.0   144503.0  \n",
      "701  1772020.0  1548247.0  \n",
      "706   109400.0   144700.0  \n",
      "Index(['Item', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013',\n",
      "       'Y2014', 'Y2015', 'Y2016'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_ten_years_fertlizers = X_ten_years_fertlizers.drop([602, 607], axis=0)\n",
    "print(X_ten_years_fertlizers)\n",
    "print(X_ten_years_fertlizers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "2009 to 2013\n",
    "## Handle missing values from 2009 to 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Y2007</th>\n",
       "      <th>Y2008</th>\n",
       "      <th>Y2009</th>\n",
       "      <th>Y2010</th>\n",
       "      <th>Y2011</th>\n",
       "      <th>Y2012</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Ammonium sulphate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160856.0</td>\n",
       "      <td>47329.0</td>\n",
       "      <td>156799.000</td>\n",
       "      <td>1.346300e+05</td>\n",
       "      <td>1.389150e+05</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>1.725810e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Calcium ammonium nitrate (CAN) and other mixtu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>591585.5</td>\n",
       "      <td>269525.0</td>\n",
       "      <td>640432.500</td>\n",
       "      <td>1.429601e+05</td>\n",
       "      <td>3.795407e+05</td>\n",
       "      <td>493617.0</td>\n",
       "      <td>4.866507e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Diammonium phosphate (DAP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208399.0</td>\n",
       "      <td>1022315.0</td>\n",
       "      <td>491721.0</td>\n",
       "      <td>1124066.000</td>\n",
       "      <td>1.512902e+05</td>\n",
       "      <td>6.201663e+05</td>\n",
       "      <td>795234.0</td>\n",
       "      <td>8.007203e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Monoammonium phosphate (MAP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416724.0</td>\n",
       "      <td>1140502.5</td>\n",
       "      <td>713917.0</td>\n",
       "      <td>987748.375</td>\n",
       "      <td>1.596203e+05</td>\n",
       "      <td>8.607920e+05</td>\n",
       "      <td>1096851.0</td>\n",
       "      <td>1.114790e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>NPK fertilizers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41037.0</td>\n",
       "      <td>1258690.0</td>\n",
       "      <td>116990.0</td>\n",
       "      <td>851430.750</td>\n",
       "      <td>1.679504e+05</td>\n",
       "      <td>6.114990e+05</td>\n",
       "      <td>700425.5</td>\n",
       "      <td>6.631195e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Other nitrogenous fertilizers, n.e.c.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21622.5</td>\n",
       "      <td>636426.0</td>\n",
       "      <td>79886.5</td>\n",
       "      <td>715113.125</td>\n",
       "      <td>1.762806e+05</td>\n",
       "      <td>3.622060e+05</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>2.114490e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Other NP compounds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>14162.0</td>\n",
       "      <td>42783.0</td>\n",
       "      <td>578795.500</td>\n",
       "      <td>1.846107e+05</td>\n",
       "      <td>3.557430e+05</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>2.364680e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Other phosphatic fertilizers, n.e.c.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>19317.0</td>\n",
       "      <td>21696.0</td>\n",
       "      <td>442477.875</td>\n",
       "      <td>1.929408e+05</td>\n",
       "      <td>3.492800e+05</td>\n",
       "      <td>413000.0</td>\n",
       "      <td>2.614870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>PK compounds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>24472.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>306160.250</td>\n",
       "      <td>2.012709e+05</td>\n",
       "      <td>2.904025e+05</td>\n",
       "      <td>326418.0</td>\n",
       "      <td>2.231370e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Potassium chloride (muriate of potash) (MOP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>29627.0</td>\n",
       "      <td>221515.0</td>\n",
       "      <td>169842.625</td>\n",
       "      <td>2.096010e+05</td>\n",
       "      <td>2.315250e+05</td>\n",
       "      <td>239836.0</td>\n",
       "      <td>1.847870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Potassium nitrate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5786.0</td>\n",
       "      <td>34782.0</td>\n",
       "      <td>12869.0</td>\n",
       "      <td>33525.000</td>\n",
       "      <td>3.105353e+05</td>\n",
       "      <td>4.097600e+04</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>4.801900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Potassium sulphate (sulphate of potash) (SOP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21154.0</td>\n",
       "      <td>176501.0</td>\n",
       "      <td>50525.0</td>\n",
       "      <td>128454.000</td>\n",
       "      <td>4.114697e+05</td>\n",
       "      <td>3.365890e+05</td>\n",
       "      <td>405500.0</td>\n",
       "      <td>3.927690e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Superphosphates above 35%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78618.0</td>\n",
       "      <td>961962.0</td>\n",
       "      <td>89395.0</td>\n",
       "      <td>899764.000</td>\n",
       "      <td>5.124040e+05</td>\n",
       "      <td>6.322020e+05</td>\n",
       "      <td>752000.0</td>\n",
       "      <td>7.375190e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Superphosphates, other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>409561.5</td>\n",
       "      <td>1009741.0</td>\n",
       "      <td>787513.0</td>\n",
       "      <td>1028638.000</td>\n",
       "      <td>1.240020e+05</td>\n",
       "      <td>1.610010e+05</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1.445030e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Urea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740505.0</td>\n",
       "      <td>1057520.0</td>\n",
       "      <td>1485631.0</td>\n",
       "      <td>1157512.000</td>\n",
       "      <td>1.092540e+06</td>\n",
       "      <td>1.753221e+06</td>\n",
       "      <td>1772020.0</td>\n",
       "      <td>1.548247e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>Urea and ammonium nitrate solutions (UAN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110721.0</td>\n",
       "      <td>231981.0</td>\n",
       "      <td>1485631.0</td>\n",
       "      <td>273876.000</td>\n",
       "      <td>1.437090e+05</td>\n",
       "      <td>1.224000e+05</td>\n",
       "      <td>109400.0</td>\n",
       "      <td>1.447000e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Item  Y2007  Y2008  \\\n",
       "613                                  Ammonium sulphate    NaN    NaN   \n",
       "618  Calcium ammonium nitrate (CAN) and other mixtu...    NaN    NaN   \n",
       "624                         Diammonium phosphate (DAP)    NaN    NaN   \n",
       "634                       Monoammonium phosphate (MAP)    NaN    NaN   \n",
       "639                                    NPK fertilizers    NaN    NaN   \n",
       "644              Other nitrogenous fertilizers, n.e.c.    NaN    NaN   \n",
       "649                                 Other NP compounds    NaN    NaN   \n",
       "654               Other phosphatic fertilizers, n.e.c.    NaN    NaN   \n",
       "667                                       PK compounds    NaN    NaN   \n",
       "672       Potassium chloride (muriate of potash) (MOP)    NaN    NaN   \n",
       "677                                  Potassium nitrate    NaN    NaN   \n",
       "682      Potassium sulphate (sulphate of potash) (SOP)    NaN    NaN   \n",
       "691                          Superphosphates above 35%    NaN    NaN   \n",
       "695                             Superphosphates, other    NaN    NaN   \n",
       "701                                               Urea    NaN    NaN   \n",
       "706          Urea and ammonium nitrate solutions (UAN)    NaN    NaN   \n",
       "\n",
       "        Y2009      Y2010      Y2011        Y2012         Y2013         Y2014  \\\n",
       "613       NaN   160856.0    47329.0   156799.000  1.346300e+05  1.389150e+05   \n",
       "618      74.0   591585.5   269525.0   640432.500  1.429601e+05  3.795407e+05   \n",
       "624  208399.0  1022315.0   491721.0  1124066.000  1.512902e+05  6.201663e+05   \n",
       "634  416724.0  1140502.5   713917.0   987748.375  1.596203e+05  8.607920e+05   \n",
       "639   41037.0  1258690.0   116990.0   851430.750  1.679504e+05  6.114990e+05   \n",
       "644   21622.5   636426.0    79886.5   715113.125  1.762806e+05  3.622060e+05   \n",
       "649    2208.0    14162.0    42783.0   578795.500  1.846107e+05  3.557430e+05   \n",
       "654    1169.0    19317.0    21696.0   442477.875  1.929408e+05  3.492800e+05   \n",
       "667     130.0    24472.0      609.0   306160.250  2.012709e+05  2.904025e+05   \n",
       "672    2958.0    29627.0   221515.0   169842.625  2.096010e+05  2.315250e+05   \n",
       "677    5786.0    34782.0    12869.0    33525.000  3.105353e+05  4.097600e+04   \n",
       "682   21154.0   176501.0    50525.0   128454.000  4.114697e+05  3.365890e+05   \n",
       "691   78618.0   961962.0    89395.0   899764.000  5.124040e+05  6.322020e+05   \n",
       "695  409561.5  1009741.0   787513.0  1028638.000  1.240020e+05  1.610010e+05   \n",
       "701  740505.0  1057520.0  1485631.0  1157512.000  1.092540e+06  1.753221e+06   \n",
       "706  110721.0   231981.0  1485631.0   273876.000  1.437090e+05  1.224000e+05   \n",
       "\n",
       "         Y2015         Y2016  \n",
       "613   192000.0  1.725810e+05  \n",
       "618   493617.0  4.866507e+05  \n",
       "624   795234.0  8.007203e+05  \n",
       "634  1096851.0  1.114790e+06  \n",
       "639   700425.5  6.631195e+05  \n",
       "644   304000.0  2.114490e+05  \n",
       "649   358500.0  2.364680e+05  \n",
       "654   413000.0  2.614870e+05  \n",
       "667   326418.0  2.231370e+05  \n",
       "672   239836.0  1.847870e+05  \n",
       "677    59000.0  4.801900e+04  \n",
       "682   405500.0  3.927690e+05  \n",
       "691   752000.0  7.375190e+05  \n",
       "695   198000.0  1.445030e+05  \n",
       "701  1772020.0  1.548247e+06  \n",
       "706   109400.0  1.447000e+05  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolate_2009_to_2016 = X_ten_years_fertlizers.interpolate()\n",
    "interpolate_2009_to_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    " Interpolate missing fertlizers data<br>\n",
    " Replace na with mean values of 2004,2005,2009,2010\n",
    "##  Replace 2007 nan values with the mean of 2004 and 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 2004 and 2005 ==== \n",
      "\n",
      "         Y2004      Y2005        mean\n",
      "613   306786.0   300505.0   303645.50\n",
      "618    12971.0    27814.0    20392.50\n",
      "624    70628.0    75753.0    73190.50\n",
      "634   128285.0   123692.0   125988.50\n",
      "639   185942.0   171631.0   178786.50\n",
      "644   243599.0   219570.0   231584.50\n",
      "649   301256.0   267509.0   284382.50\n",
      "654   358913.0   315448.0   337180.50\n",
      "667   416570.0   363387.0   389978.50\n",
      "672   474227.0   411326.0   442776.50\n",
      "677   248199.5   220003.0   234101.25\n",
      "682    22172.0    28680.0    25426.00\n",
      "691   266833.0   295474.0   281153.50\n",
      "695  1228800.0  1142900.0  1185850.00\n",
      "701  1469362.0  1405955.0  1437658.50\n",
      "706  1469362.0  1405955.0  1437658.50\n"
     ]
    }
   ],
   "source": [
    "interpolate_2004_2005 = Australia_Fertilizers_Products_Agricultural[['Y2004','Y2005']].copy().interpolate()\n",
    "index_names = interpolate_2004_2005.index\n",
    "index_names\n",
    "interpolate_2004_2005=interpolate_2004_2005.drop([602,607], axis=0)\n",
    "interpolate_2004_2005['mean'] = interpolate_2004_2005.mean(axis=1)\n",
    "print(\"Mean of 2004 and 2005 ==== \\n\")\n",
    "print(interpolate_2004_2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this for 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Replace 2008 nan values with the mean of 2009 and 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([602, 607, 613, 618, 624, 634, 639, 644, 649, 654, 667, 672, 677,\n",
       "            682, 691, 695, 701, 706],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolate_2009_2010 = Australia_Fertilizers_Products_Agricultural[['Y2009','Y2010']].copy().interpolate()\n",
    "index_names = interpolate_2009_2010.index\n",
    "index_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 2009 and 2010 ==== \n",
      "\n",
      "        Y2009      Y2010       mean\n",
      "613       NaN   160856.0  160856.00\n",
      "618      74.0   591585.5  295829.75\n",
      "624  208399.0  1022315.0  615357.00\n",
      "634  416724.0  1140502.5  778613.25\n",
      "639   41037.0  1258690.0  649863.50\n",
      "644   21622.5   636426.0  329024.25\n",
      "649    2208.0    14162.0    8185.00\n",
      "654    1169.0    19317.0   10243.00\n",
      "667     130.0    24472.0   12301.00\n",
      "672    2958.0    29627.0   16292.50\n",
      "677    5786.0    34782.0   20284.00\n",
      "682   21154.0   176501.0   98827.50\n",
      "691   78618.0   961962.0  520290.00\n",
      "695  409561.5  1009741.0  709651.25\n",
      "701  740505.0  1057520.0  899012.50\n",
      "706  110721.0   231981.0  171351.00\n"
     ]
    }
   ],
   "source": [
    "interpolate_2009_2010['mean'] = interpolate_2009_2010.mean(axis=1)\n",
    "print(\"Mean of 2009 and 2010 ==== \\n\")\n",
    "# Use this for 2008\n",
    "interpolate_2009_2010=interpolate_2009_2010.drop([602,607], axis=0)\n",
    "print(interpolate_2009_2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate 2007 nan values with computed mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(1,16):\n",
    "       interpolate_2009_to_2016.iloc[0:i,1:2] = interpolate_2004_2005['mean'].iloc[0:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate 2008 nan values with computed mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437658.5\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for j in range(1,16):\n",
    "       interpolate_2009_to_2016.iloc[0:j,2:3] = interpolate_2009_2010['mean'].iloc[0:j]\n",
    "        \n",
    "    \n",
    "interpolate_2009_to_2016.iloc[15, 1] = 1437658.50\n",
    "print(interpolate_2009_to_2016.iloc[15, 1])\n",
    "interpolate_2009_to_2016.iloc[15, 2] = 171351.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Y2007</th>\n",
       "      <th>Y2008</th>\n",
       "      <th>Y2009</th>\n",
       "      <th>Y2010</th>\n",
       "      <th>Y2011</th>\n",
       "      <th>Y2012</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Ammonium sulphate</td>\n",
       "      <td>303645.50</td>\n",
       "      <td>160856.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160856.0</td>\n",
       "      <td>47329.0</td>\n",
       "      <td>156799.000</td>\n",
       "      <td>1.346300e+05</td>\n",
       "      <td>1.389150e+05</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>1.725810e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Calcium ammonium nitrate (CAN) and other mixtu...</td>\n",
       "      <td>20392.50</td>\n",
       "      <td>295829.75</td>\n",
       "      <td>74.0</td>\n",
       "      <td>591585.5</td>\n",
       "      <td>269525.0</td>\n",
       "      <td>640432.500</td>\n",
       "      <td>1.429601e+05</td>\n",
       "      <td>3.795407e+05</td>\n",
       "      <td>493617.0</td>\n",
       "      <td>4.866507e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Diammonium phosphate (DAP)</td>\n",
       "      <td>73190.50</td>\n",
       "      <td>615357.00</td>\n",
       "      <td>208399.0</td>\n",
       "      <td>1022315.0</td>\n",
       "      <td>491721.0</td>\n",
       "      <td>1124066.000</td>\n",
       "      <td>1.512902e+05</td>\n",
       "      <td>6.201663e+05</td>\n",
       "      <td>795234.0</td>\n",
       "      <td>8.007203e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Monoammonium phosphate (MAP)</td>\n",
       "      <td>125988.50</td>\n",
       "      <td>778613.25</td>\n",
       "      <td>416724.0</td>\n",
       "      <td>1140502.5</td>\n",
       "      <td>713917.0</td>\n",
       "      <td>987748.375</td>\n",
       "      <td>1.596203e+05</td>\n",
       "      <td>8.607920e+05</td>\n",
       "      <td>1096851.0</td>\n",
       "      <td>1.114790e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>NPK fertilizers</td>\n",
       "      <td>178786.50</td>\n",
       "      <td>649863.50</td>\n",
       "      <td>41037.0</td>\n",
       "      <td>1258690.0</td>\n",
       "      <td>116990.0</td>\n",
       "      <td>851430.750</td>\n",
       "      <td>1.679504e+05</td>\n",
       "      <td>6.114990e+05</td>\n",
       "      <td>700425.5</td>\n",
       "      <td>6.631195e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Other nitrogenous fertilizers, n.e.c.</td>\n",
       "      <td>231584.50</td>\n",
       "      <td>329024.25</td>\n",
       "      <td>21622.5</td>\n",
       "      <td>636426.0</td>\n",
       "      <td>79886.5</td>\n",
       "      <td>715113.125</td>\n",
       "      <td>1.762806e+05</td>\n",
       "      <td>3.622060e+05</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>2.114490e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Other NP compounds</td>\n",
       "      <td>284382.50</td>\n",
       "      <td>8185.00</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>14162.0</td>\n",
       "      <td>42783.0</td>\n",
       "      <td>578795.500</td>\n",
       "      <td>1.846107e+05</td>\n",
       "      <td>3.557430e+05</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>2.364680e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Other phosphatic fertilizers, n.e.c.</td>\n",
       "      <td>337180.50</td>\n",
       "      <td>10243.00</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>19317.0</td>\n",
       "      <td>21696.0</td>\n",
       "      <td>442477.875</td>\n",
       "      <td>1.929408e+05</td>\n",
       "      <td>3.492800e+05</td>\n",
       "      <td>413000.0</td>\n",
       "      <td>2.614870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>PK compounds</td>\n",
       "      <td>389978.50</td>\n",
       "      <td>12301.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>24472.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>306160.250</td>\n",
       "      <td>2.012709e+05</td>\n",
       "      <td>2.904025e+05</td>\n",
       "      <td>326418.0</td>\n",
       "      <td>2.231370e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Potassium chloride (muriate of potash) (MOP)</td>\n",
       "      <td>442776.50</td>\n",
       "      <td>16292.50</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>29627.0</td>\n",
       "      <td>221515.0</td>\n",
       "      <td>169842.625</td>\n",
       "      <td>2.096010e+05</td>\n",
       "      <td>2.315250e+05</td>\n",
       "      <td>239836.0</td>\n",
       "      <td>1.847870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Potassium nitrate</td>\n",
       "      <td>234101.25</td>\n",
       "      <td>20284.00</td>\n",
       "      <td>5786.0</td>\n",
       "      <td>34782.0</td>\n",
       "      <td>12869.0</td>\n",
       "      <td>33525.000</td>\n",
       "      <td>3.105353e+05</td>\n",
       "      <td>4.097600e+04</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>4.801900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Potassium sulphate (sulphate of potash) (SOP)</td>\n",
       "      <td>25426.00</td>\n",
       "      <td>98827.50</td>\n",
       "      <td>21154.0</td>\n",
       "      <td>176501.0</td>\n",
       "      <td>50525.0</td>\n",
       "      <td>128454.000</td>\n",
       "      <td>4.114697e+05</td>\n",
       "      <td>3.365890e+05</td>\n",
       "      <td>405500.0</td>\n",
       "      <td>3.927690e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Superphosphates above 35%</td>\n",
       "      <td>281153.50</td>\n",
       "      <td>520290.00</td>\n",
       "      <td>78618.0</td>\n",
       "      <td>961962.0</td>\n",
       "      <td>89395.0</td>\n",
       "      <td>899764.000</td>\n",
       "      <td>5.124040e+05</td>\n",
       "      <td>6.322020e+05</td>\n",
       "      <td>752000.0</td>\n",
       "      <td>7.375190e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Superphosphates, other</td>\n",
       "      <td>1185850.00</td>\n",
       "      <td>709651.25</td>\n",
       "      <td>409561.5</td>\n",
       "      <td>1009741.0</td>\n",
       "      <td>787513.0</td>\n",
       "      <td>1028638.000</td>\n",
       "      <td>1.240020e+05</td>\n",
       "      <td>1.610010e+05</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1.445030e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Urea</td>\n",
       "      <td>1437658.50</td>\n",
       "      <td>899012.50</td>\n",
       "      <td>740505.0</td>\n",
       "      <td>1057520.0</td>\n",
       "      <td>1485631.0</td>\n",
       "      <td>1157512.000</td>\n",
       "      <td>1.092540e+06</td>\n",
       "      <td>1.753221e+06</td>\n",
       "      <td>1772020.0</td>\n",
       "      <td>1.548247e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>Urea and ammonium nitrate solutions (UAN)</td>\n",
       "      <td>1437658.50</td>\n",
       "      <td>171351.00</td>\n",
       "      <td>110721.0</td>\n",
       "      <td>231981.0</td>\n",
       "      <td>1485631.0</td>\n",
       "      <td>273876.000</td>\n",
       "      <td>1.437090e+05</td>\n",
       "      <td>1.224000e+05</td>\n",
       "      <td>109400.0</td>\n",
       "      <td>1.447000e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Item       Y2007      Y2008  \\\n",
       "613                                  Ammonium sulphate   303645.50  160856.00   \n",
       "618  Calcium ammonium nitrate (CAN) and other mixtu...    20392.50  295829.75   \n",
       "624                         Diammonium phosphate (DAP)    73190.50  615357.00   \n",
       "634                       Monoammonium phosphate (MAP)   125988.50  778613.25   \n",
       "639                                    NPK fertilizers   178786.50  649863.50   \n",
       "644              Other nitrogenous fertilizers, n.e.c.   231584.50  329024.25   \n",
       "649                                 Other NP compounds   284382.50    8185.00   \n",
       "654               Other phosphatic fertilizers, n.e.c.   337180.50   10243.00   \n",
       "667                                       PK compounds   389978.50   12301.00   \n",
       "672       Potassium chloride (muriate of potash) (MOP)   442776.50   16292.50   \n",
       "677                                  Potassium nitrate   234101.25   20284.00   \n",
       "682      Potassium sulphate (sulphate of potash) (SOP)    25426.00   98827.50   \n",
       "691                          Superphosphates above 35%   281153.50  520290.00   \n",
       "695                             Superphosphates, other  1185850.00  709651.25   \n",
       "701                                               Urea  1437658.50  899012.50   \n",
       "706          Urea and ammonium nitrate solutions (UAN)  1437658.50  171351.00   \n",
       "\n",
       "        Y2009      Y2010      Y2011        Y2012         Y2013         Y2014  \\\n",
       "613       NaN   160856.0    47329.0   156799.000  1.346300e+05  1.389150e+05   \n",
       "618      74.0   591585.5   269525.0   640432.500  1.429601e+05  3.795407e+05   \n",
       "624  208399.0  1022315.0   491721.0  1124066.000  1.512902e+05  6.201663e+05   \n",
       "634  416724.0  1140502.5   713917.0   987748.375  1.596203e+05  8.607920e+05   \n",
       "639   41037.0  1258690.0   116990.0   851430.750  1.679504e+05  6.114990e+05   \n",
       "644   21622.5   636426.0    79886.5   715113.125  1.762806e+05  3.622060e+05   \n",
       "649    2208.0    14162.0    42783.0   578795.500  1.846107e+05  3.557430e+05   \n",
       "654    1169.0    19317.0    21696.0   442477.875  1.929408e+05  3.492800e+05   \n",
       "667     130.0    24472.0      609.0   306160.250  2.012709e+05  2.904025e+05   \n",
       "672    2958.0    29627.0   221515.0   169842.625  2.096010e+05  2.315250e+05   \n",
       "677    5786.0    34782.0    12869.0    33525.000  3.105353e+05  4.097600e+04   \n",
       "682   21154.0   176501.0    50525.0   128454.000  4.114697e+05  3.365890e+05   \n",
       "691   78618.0   961962.0    89395.0   899764.000  5.124040e+05  6.322020e+05   \n",
       "695  409561.5  1009741.0   787513.0  1028638.000  1.240020e+05  1.610010e+05   \n",
       "701  740505.0  1057520.0  1485631.0  1157512.000  1.092540e+06  1.753221e+06   \n",
       "706  110721.0   231981.0  1485631.0   273876.000  1.437090e+05  1.224000e+05   \n",
       "\n",
       "         Y2015         Y2016  \n",
       "613   192000.0  1.725810e+05  \n",
       "618   493617.0  4.866507e+05  \n",
       "624   795234.0  8.007203e+05  \n",
       "634  1096851.0  1.114790e+06  \n",
       "639   700425.5  6.631195e+05  \n",
       "644   304000.0  2.114490e+05  \n",
       "649   358500.0  2.364680e+05  \n",
       "654   413000.0  2.614870e+05  \n",
       "667   326418.0  2.231370e+05  \n",
       "672   239836.0  1.847870e+05  \n",
       "677    59000.0  4.801900e+04  \n",
       "682   405500.0  3.927690e+05  \n",
       "691   752000.0  7.375190e+05  \n",
       "695   198000.0  1.445030e+05  \n",
       "701  1772020.0  1.548247e+06  \n",
       "706   109400.0  1.447000e+05  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ten_years_fertilizers_interpolated = interpolate_2009_to_2016\n",
    "X_ten_years_fertilizers_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Combine pesticdes and fertilizers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Item     Y2007     Y2008     Y2009     Y2010  \\\n",
      "160           Pesticides (total)  32446.24  42935.38  38065.69  42169.39   \n",
      "161                 Insecticides   7262.97   9610.92   8520.86   9439.46   \n",
      "162                   Herbicides  22403.90  29646.57  26284.08  29117.66   \n",
      "163  Fungicides and Bactericides   2324.91   3076.50   2727.56   3021.61   \n",
      "164         Other Pesticides nes    454.47    601.39    533.18    590.66   \n",
      "165         Other Pesticides nes    454.47    601.39    533.18    590.66   \n",
      "\n",
      "        Y2011     Y2012     Y2013     Y2014     Y2015     Y2016  \n",
      "160  47632.98  48687.88  45177.19  49857.35  50921.60  63416.48  \n",
      "161  10662.47  10898.60  10112.74  11160.38  11398.61  14195.54  \n",
      "162  32890.23  33618.62  31194.52  34426.14  35161.00  43788.62  \n",
      "163   3413.10   3488.69   3237.13   3572.49   3648.74   4544.05  \n",
      "164    667.19    681.97    632.79    698.35    713.25    888.27  \n",
      "165    667.19    681.97    632.79    698.35    713.25    888.27  \n",
      "                                                  Item       Y2007      Y2008  \\\n",
      "613                                  Ammonium sulphate   303645.50  160856.00   \n",
      "618  Calcium ammonium nitrate (CAN) and other mixtu...    20392.50  295829.75   \n",
      "624                         Diammonium phosphate (DAP)    73190.50  615357.00   \n",
      "634                       Monoammonium phosphate (MAP)   125988.50  778613.25   \n",
      "639                                    NPK fertilizers   178786.50  649863.50   \n",
      "644              Other nitrogenous fertilizers, n.e.c.   231584.50  329024.25   \n",
      "649                                 Other NP compounds   284382.50    8185.00   \n",
      "654               Other phosphatic fertilizers, n.e.c.   337180.50   10243.00   \n",
      "667                                       PK compounds   389978.50   12301.00   \n",
      "672       Potassium chloride (muriate of potash) (MOP)   442776.50   16292.50   \n",
      "677                                  Potassium nitrate   234101.25   20284.00   \n",
      "682      Potassium sulphate (sulphate of potash) (SOP)    25426.00   98827.50   \n",
      "691                          Superphosphates above 35%   281153.50  520290.00   \n",
      "695                             Superphosphates, other  1185850.00  709651.25   \n",
      "701                                               Urea  1437658.50  899012.50   \n",
      "706          Urea and ammonium nitrate solutions (UAN)  1437658.50  171351.00   \n",
      "\n",
      "        Y2009      Y2010      Y2011        Y2012         Y2013         Y2014  \\\n",
      "613       NaN   160856.0    47329.0   156799.000  1.346300e+05  1.389150e+05   \n",
      "618      74.0   591585.5   269525.0   640432.500  1.429601e+05  3.795407e+05   \n",
      "624  208399.0  1022315.0   491721.0  1124066.000  1.512902e+05  6.201663e+05   \n",
      "634  416724.0  1140502.5   713917.0   987748.375  1.596203e+05  8.607920e+05   \n",
      "639   41037.0  1258690.0   116990.0   851430.750  1.679504e+05  6.114990e+05   \n",
      "644   21622.5   636426.0    79886.5   715113.125  1.762806e+05  3.622060e+05   \n",
      "649    2208.0    14162.0    42783.0   578795.500  1.846107e+05  3.557430e+05   \n",
      "654    1169.0    19317.0    21696.0   442477.875  1.929408e+05  3.492800e+05   \n",
      "667     130.0    24472.0      609.0   306160.250  2.012709e+05  2.904025e+05   \n",
      "672    2958.0    29627.0   221515.0   169842.625  2.096010e+05  2.315250e+05   \n",
      "677    5786.0    34782.0    12869.0    33525.000  3.105353e+05  4.097600e+04   \n",
      "682   21154.0   176501.0    50525.0   128454.000  4.114697e+05  3.365890e+05   \n",
      "691   78618.0   961962.0    89395.0   899764.000  5.124040e+05  6.322020e+05   \n",
      "695  409561.5  1009741.0   787513.0  1028638.000  1.240020e+05  1.610010e+05   \n",
      "701  740505.0  1057520.0  1485631.0  1157512.000  1.092540e+06  1.753221e+06   \n",
      "706  110721.0   231981.0  1485631.0   273876.000  1.437090e+05  1.224000e+05   \n",
      "\n",
      "         Y2015         Y2016  \n",
      "613   192000.0  1.725810e+05  \n",
      "618   493617.0  4.866507e+05  \n",
      "624   795234.0  8.007203e+05  \n",
      "634  1096851.0  1.114790e+06  \n",
      "639   700425.5  6.631195e+05  \n",
      "644   304000.0  2.114490e+05  \n",
      "649   358500.0  2.364680e+05  \n",
      "654   413000.0  2.614870e+05  \n",
      "667   326418.0  2.231370e+05  \n",
      "672   239836.0  1.847870e+05  \n",
      "677    59000.0  4.801900e+04  \n",
      "682   405500.0  3.927690e+05  \n",
      "691   752000.0  7.375190e+05  \n",
      "695   198000.0  1.445030e+05  \n",
      "701  1772020.0  1.548247e+06  \n",
      "706   109400.0  1.447000e+05  \n",
      "[['Pesticides (total)' 32446.24 42935.38 38065.69 42169.39 47632.98\n",
      "  48687.88 45177.19 49857.35 50921.6 63416.48]\n",
      " ['Insecticides' 7262.97 9610.92 8520.86 9439.46 10662.47 10898.6\n",
      "  10112.74 11160.38 11398.61 14195.54]\n",
      " ['Herbicides' 22403.9 29646.57 26284.08 29117.66 32890.23 33618.62\n",
      "  31194.52 34426.14 35161.0 43788.62]\n",
      " ['Fungicides and Bactericides' 2324.91 3076.5 2727.56 3021.61 3413.1\n",
      "  3488.69 3237.13 3572.49 3648.74 4544.05]\n",
      " ['Other Pesticides nes' 454.47 601.39 533.18 590.66 667.19 681.97 632.79\n",
      "  698.35 713.25 888.27]\n",
      " ['Other Pesticides nes' 454.47 601.39 533.18 590.66 667.19 681.97 632.79\n",
      "  698.35 713.25 888.27]]\n",
      "[['Ammonium sulphate' 303645.5 160856.0 nan 160856.0 47329.0 156799.0\n",
      "  134630.0 138915.0 192000.0 172581.0]\n",
      " ['Calcium ammonium nitrate (CAN) and other mixtures with calcium carbonate'\n",
      "  20392.5 295829.75 74.0 591585.5 269525.0 640432.5 142960.11111111112\n",
      "  379540.6666666666 493617.0 486650.6666666667]\n",
      " ['Diammonium phosphate (DAP)' 73190.5 615357.0 208399.0 1022315.0\n",
      "  491721.0 1124066.0 151290.22222222222 620166.3333333333 795234.0\n",
      "  800720.3333333334]\n",
      " ['Monoammonium phosphate (MAP)' 125988.5 778613.25 416724.0 1140502.5\n",
      "  713917.0 987748.375 159620.33333333334 860792.0 1096851.0 1114790.0]\n",
      " ['NPK fertilizers' 178786.5 649863.5 41037.0 1258690.0 116990.0\n",
      "  851430.75 167950.44444444444 611499.0 700425.5 663119.5]\n",
      " ['Other nitrogenous fertilizers, n.e.c.' 231584.5 329024.25 21622.5\n",
      "  636426.0 79886.5 715113.125 176280.55555555556 362206.0 304000.0\n",
      "  211449.0]\n",
      " ['Other NP compounds' 284382.5 8185.0 2208.0 14162.0 42783.0 578795.5\n",
      "  184610.6666666667 355743.0 358500.0 236468.0]\n",
      " ['Other phosphatic fertilizers, n.e.c.' 337180.5 10243.0 1169.0 19317.0\n",
      "  21696.0 442477.875 192940.77777777778 349280.0 413000.0 261487.0]\n",
      " ['PK compounds' 389978.5 12301.0 130.0 24472.0 609.0 306160.25\n",
      "  201270.88888888888 290402.5 326418.0 223137.0]\n",
      " ['Potassium chloride (muriate of potash) (MOP)' 442776.5 16292.5 2958.0\n",
      "  29627.0 221515.0 169842.625 209601.0 231525.0 239836.0 184787.0]\n",
      " ['Potassium nitrate' 234101.25 20284.0 5786.0 34782.0 12869.0 33525.0\n",
      "  310535.3333333333 40976.0 59000.0 48019.0]\n",
      " ['Potassium sulphate (sulphate of potash) (SOP)' 25426.0 98827.5 21154.0\n",
      "  176501.0 50525.0 128454.0 411469.6666666666 336589.0 405500.0 392769.0]\n",
      " ['Superphosphates above 35%' 281153.5 520290.0 78618.0 961962.0 89395.0\n",
      "  899764.0 512404.0 632202.0 752000.0 737519.0]\n",
      " ['Superphosphates, other' 1185850.0 709651.25 409561.5 1009741.0\n",
      "  787513.0 1028638.0 124002.0 161001.0 198000.0 144503.0]\n",
      " ['Urea' 1437658.5 899012.5 740505.0 1057520.0 1485631.0 1157512.0\n",
      "  1092540.0 1753221.0 1772020.0 1548247.0]\n",
      " ['Urea and ammonium nitrate solutions (UAN)' 1437658.5 171351.0 110721.0\n",
      "  231981.0 1485631.0 273876.0 143709.0 122400.0 109400.0 144700.0]]\n",
      "        Y2007     Y2008     Y2009     Y2010     Y2011     Y2012     Y2013  \\\n",
      "160  32446.24  42935.38  38065.69  42169.39  47632.98  48687.88  45177.19   \n",
      "161   7262.97   9610.92   8520.86   9439.46  10662.47  10898.60  10112.74   \n",
      "162  22403.90  29646.57  26284.08  29117.66  32890.23  33618.62  31194.52   \n",
      "163   2324.91   3076.50   2727.56   3021.61   3413.10   3488.69   3237.13   \n",
      "164    454.47    601.39    533.18    590.66    667.19    681.97    632.79   \n",
      "165    454.47    601.39    533.18    590.66    667.19    681.97    632.79   \n",
      "\n",
      "        Y2014     Y2015     Y2016  \n",
      "160  49857.35  50921.60  63416.48  \n",
      "161  11160.38  11398.61  14195.54  \n",
      "162  34426.14  35161.00  43788.62  \n",
      "163   3572.49   3648.74   4544.05  \n",
      "164    698.35    713.25    888.27  \n",
      "165    698.35    713.25    888.27  \n",
      "\t Pesticides tensor tensor([[32446.2400, 42935.3800, 38065.6900, 42169.3900, 47632.9800, 48687.8800,\n",
      "         45177.1900, 49857.3500, 50921.6000, 63416.4800],\n",
      "        [ 7262.9700,  9610.9200,  8520.8600,  9439.4600, 10662.4700, 10898.6000,\n",
      "         10112.7400, 11160.3800, 11398.6100, 14195.5400],\n",
      "        [22403.9000, 29646.5700, 26284.0800, 29117.6600, 32890.2300, 33618.6200,\n",
      "         31194.5200, 34426.1400, 35161.0000, 43788.6200],\n",
      "        [ 2324.9100,  3076.5000,  2727.5600,  3021.6100,  3413.1000,  3488.6900,\n",
      "          3237.1300,  3572.4900,  3648.7400,  4544.0500],\n",
      "        [  454.4700,   601.3900,   533.1800,   590.6600,   667.1900,   681.9700,\n",
      "           632.7900,   698.3500,   713.2500,   888.2700],\n",
      "        [  454.4700,   601.3900,   533.1800,   590.6600,   667.1900,   681.9700,\n",
      "           632.7900,   698.3500,   713.2500,   888.2700]], dtype=torch.float64)\n",
      "          Y2007      Y2008     Y2009      Y2010      Y2011        Y2012  \\\n",
      "613   303645.50  160856.00       NaN   160856.0    47329.0   156799.000   \n",
      "618    20392.50  295829.75      74.0   591585.5   269525.0   640432.500   \n",
      "624    73190.50  615357.00  208399.0  1022315.0   491721.0  1124066.000   \n",
      "634   125988.50  778613.25  416724.0  1140502.5   713917.0   987748.375   \n",
      "639   178786.50  649863.50   41037.0  1258690.0   116990.0   851430.750   \n",
      "644   231584.50  329024.25   21622.5   636426.0    79886.5   715113.125   \n",
      "649   284382.50    8185.00    2208.0    14162.0    42783.0   578795.500   \n",
      "654   337180.50   10243.00    1169.0    19317.0    21696.0   442477.875   \n",
      "667   389978.50   12301.00     130.0    24472.0      609.0   306160.250   \n",
      "672   442776.50   16292.50    2958.0    29627.0   221515.0   169842.625   \n",
      "677   234101.25   20284.00    5786.0    34782.0    12869.0    33525.000   \n",
      "682    25426.00   98827.50   21154.0   176501.0    50525.0   128454.000   \n",
      "691   281153.50  520290.00   78618.0   961962.0    89395.0   899764.000   \n",
      "695  1185850.00  709651.25  409561.5  1009741.0   787513.0  1028638.000   \n",
      "701  1437658.50  899012.50  740505.0  1057520.0  1485631.0  1157512.000   \n",
      "706  1437658.50  171351.00  110721.0   231981.0  1485631.0   273876.000   \n",
      "\n",
      "            Y2013         Y2014      Y2015         Y2016  \n",
      "613  1.346300e+05  1.389150e+05   192000.0  1.725810e+05  \n",
      "618  1.429601e+05  3.795407e+05   493617.0  4.866507e+05  \n",
      "624  1.512902e+05  6.201663e+05   795234.0  8.007203e+05  \n",
      "634  1.596203e+05  8.607920e+05  1096851.0  1.114790e+06  \n",
      "639  1.679504e+05  6.114990e+05   700425.5  6.631195e+05  \n",
      "644  1.762806e+05  3.622060e+05   304000.0  2.114490e+05  \n",
      "649  1.846107e+05  3.557430e+05   358500.0  2.364680e+05  \n",
      "654  1.929408e+05  3.492800e+05   413000.0  2.614870e+05  \n",
      "667  2.012709e+05  2.904025e+05   326418.0  2.231370e+05  \n",
      "672  2.096010e+05  2.315250e+05   239836.0  1.847870e+05  \n",
      "677  3.105353e+05  4.097600e+04    59000.0  4.801900e+04  \n",
      "682  4.114697e+05  3.365890e+05   405500.0  3.927690e+05  \n",
      "691  5.124040e+05  6.322020e+05   752000.0  7.375190e+05  \n",
      "695  1.240020e+05  1.610010e+05   198000.0  1.445030e+05  \n",
      "701  1.092540e+06  1.753221e+06  1772020.0  1.548247e+06  \n",
      "706  1.437090e+05  1.224000e+05   109400.0  1.447000e+05  \n",
      "\t Fertilizers tensor tensor([[3.0365e+05, 1.6086e+05,        nan, 1.6086e+05, 4.7329e+04, 1.5680e+05,\n",
      "         1.3463e+05, 1.3892e+05, 1.9200e+05, 1.7258e+05],\n",
      "        [2.0392e+04, 2.9583e+05, 7.4000e+01, 5.9159e+05, 2.6952e+05, 6.4043e+05,\n",
      "         1.4296e+05, 3.7954e+05, 4.9362e+05, 4.8665e+05],\n",
      "        [7.3190e+04, 6.1536e+05, 2.0840e+05, 1.0223e+06, 4.9172e+05, 1.1241e+06,\n",
      "         1.5129e+05, 6.2017e+05, 7.9523e+05, 8.0072e+05],\n",
      "        [1.2599e+05, 7.7861e+05, 4.1672e+05, 1.1405e+06, 7.1392e+05, 9.8775e+05,\n",
      "         1.5962e+05, 8.6079e+05, 1.0969e+06, 1.1148e+06],\n",
      "        [1.7879e+05, 6.4986e+05, 4.1037e+04, 1.2587e+06, 1.1699e+05, 8.5143e+05,\n",
      "         1.6795e+05, 6.1150e+05, 7.0043e+05, 6.6312e+05],\n",
      "        [2.3158e+05, 3.2902e+05, 2.1622e+04, 6.3643e+05, 7.9886e+04, 7.1511e+05,\n",
      "         1.7628e+05, 3.6221e+05, 3.0400e+05, 2.1145e+05],\n",
      "        [2.8438e+05, 8.1850e+03, 2.2080e+03, 1.4162e+04, 4.2783e+04, 5.7880e+05,\n",
      "         1.8461e+05, 3.5574e+05, 3.5850e+05, 2.3647e+05],\n",
      "        [3.3718e+05, 1.0243e+04, 1.1690e+03, 1.9317e+04, 2.1696e+04, 4.4248e+05,\n",
      "         1.9294e+05, 3.4928e+05, 4.1300e+05, 2.6149e+05],\n",
      "        [3.8998e+05, 1.2301e+04, 1.3000e+02, 2.4472e+04, 6.0900e+02, 3.0616e+05,\n",
      "         2.0127e+05, 2.9040e+05, 3.2642e+05, 2.2314e+05],\n",
      "        [4.4278e+05, 1.6292e+04, 2.9580e+03, 2.9627e+04, 2.2152e+05, 1.6984e+05,\n",
      "         2.0960e+05, 2.3152e+05, 2.3984e+05, 1.8479e+05],\n",
      "        [2.3410e+05, 2.0284e+04, 5.7860e+03, 3.4782e+04, 1.2869e+04, 3.3525e+04,\n",
      "         3.1054e+05, 4.0976e+04, 5.9000e+04, 4.8019e+04],\n",
      "        [2.5426e+04, 9.8828e+04, 2.1154e+04, 1.7650e+05, 5.0525e+04, 1.2845e+05,\n",
      "         4.1147e+05, 3.3659e+05, 4.0550e+05, 3.9277e+05],\n",
      "        [2.8115e+05, 5.2029e+05, 7.8618e+04, 9.6196e+05, 8.9395e+04, 8.9976e+05,\n",
      "         5.1240e+05, 6.3220e+05, 7.5200e+05, 7.3752e+05],\n",
      "        [1.1858e+06, 7.0965e+05, 4.0956e+05, 1.0097e+06, 7.8751e+05, 1.0286e+06,\n",
      "         1.2400e+05, 1.6100e+05, 1.9800e+05, 1.4450e+05],\n",
      "        [1.4377e+06, 8.9901e+05, 7.4050e+05, 1.0575e+06, 1.4856e+06, 1.1575e+06,\n",
      "         1.0925e+06, 1.7532e+06, 1.7720e+06, 1.5482e+06],\n",
      "        [1.4377e+06, 1.7135e+05, 1.1072e+05, 2.3198e+05, 1.4856e+06, 2.7388e+05,\n",
      "         1.4371e+05, 1.2240e+05, 1.0940e+05, 1.4470e+05]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(X_ten_years_pesticides)\n",
    "print(X_ten_years_fertilizers_interpolated)\n",
    "\n",
    "pesticides_without_Item = X_ten_years_pesticides.copy().drop(['Item'], axis=1)\n",
    "fertilizers_without_Item = X_ten_years_fertilizers_interpolated.copy().drop(['Item'], axis=1)\n",
    "# torch.tensor(X_ten_years_pesticides.values.astype(np.float64))\n",
    "print(X_ten_years_pesticides.values)\n",
    "print(X_ten_years_fertilizers_interpolated.values)\n",
    "\n",
    "print(pesticides_without_Item)\n",
    "pesticides_tensor = torch.from_numpy(pesticides_without_Item.values)\n",
    "print(\"\\t Pesticides tensor\", pesticides_tensor)\n",
    "\n",
    "print(fertilizers_without_Item)\n",
    "fertilizers_tensor = torch.from_numpy(fertilizers_without_Item.values)\n",
    "print(\"\\t Fertilizers tensor\", fertilizers_tensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([22, 10])\n",
      "\n",
      "\n",
      "Training X data for 10 years:  tensor([[3.2446e+04, 4.2935e+04, 3.8066e+04, 4.2169e+04, 4.7633e+04, 4.8688e+04,\n",
      "         4.5177e+04, 4.9857e+04, 5.0922e+04, 6.3416e+04],\n",
      "        [7.2630e+03, 9.6109e+03, 8.5209e+03, 9.4395e+03, 1.0662e+04, 1.0899e+04,\n",
      "         1.0113e+04, 1.1160e+04, 1.1399e+04, 1.4196e+04],\n",
      "        [2.2404e+04, 2.9647e+04, 2.6284e+04, 2.9118e+04, 3.2890e+04, 3.3619e+04,\n",
      "         3.1195e+04, 3.4426e+04, 3.5161e+04, 4.3789e+04],\n",
      "        [2.3249e+03, 3.0765e+03, 2.7276e+03, 3.0216e+03, 3.4131e+03, 3.4887e+03,\n",
      "         3.2371e+03, 3.5725e+03, 3.6487e+03, 4.5441e+03],\n",
      "        [4.5447e+02, 6.0139e+02, 5.3318e+02, 5.9066e+02, 6.6719e+02, 6.8197e+02,\n",
      "         6.3279e+02, 6.9835e+02, 7.1325e+02, 8.8827e+02],\n",
      "        [4.5447e+02, 6.0139e+02, 5.3318e+02, 5.9066e+02, 6.6719e+02, 6.8197e+02,\n",
      "         6.3279e+02, 6.9835e+02, 7.1325e+02, 8.8827e+02],\n",
      "        [3.0365e+05, 1.6086e+05,        nan, 1.6086e+05, 4.7329e+04, 1.5680e+05,\n",
      "         1.3463e+05, 1.3892e+05, 1.9200e+05, 1.7258e+05],\n",
      "        [2.0392e+04, 2.9583e+05, 7.4000e+01, 5.9159e+05, 2.6952e+05, 6.4043e+05,\n",
      "         1.4296e+05, 3.7954e+05, 4.9362e+05, 4.8665e+05],\n",
      "        [7.3190e+04, 6.1536e+05, 2.0840e+05, 1.0223e+06, 4.9172e+05, 1.1241e+06,\n",
      "         1.5129e+05, 6.2017e+05, 7.9523e+05, 8.0072e+05],\n",
      "        [1.2599e+05, 7.7861e+05, 4.1672e+05, 1.1405e+06, 7.1392e+05, 9.8775e+05,\n",
      "         1.5962e+05, 8.6079e+05, 1.0969e+06, 1.1148e+06],\n",
      "        [1.7879e+05, 6.4986e+05, 4.1037e+04, 1.2587e+06, 1.1699e+05, 8.5143e+05,\n",
      "         1.6795e+05, 6.1150e+05, 7.0043e+05, 6.6312e+05],\n",
      "        [2.3158e+05, 3.2902e+05, 2.1622e+04, 6.3643e+05, 7.9886e+04, 7.1511e+05,\n",
      "         1.7628e+05, 3.6221e+05, 3.0400e+05, 2.1145e+05],\n",
      "        [2.8438e+05, 8.1850e+03, 2.2080e+03, 1.4162e+04, 4.2783e+04, 5.7880e+05,\n",
      "         1.8461e+05, 3.5574e+05, 3.5850e+05, 2.3647e+05],\n",
      "        [3.3718e+05, 1.0243e+04, 1.1690e+03, 1.9317e+04, 2.1696e+04, 4.4248e+05,\n",
      "         1.9294e+05, 3.4928e+05, 4.1300e+05, 2.6149e+05],\n",
      "        [3.8998e+05, 1.2301e+04, 1.3000e+02, 2.4472e+04, 6.0900e+02, 3.0616e+05,\n",
      "         2.0127e+05, 2.9040e+05, 3.2642e+05, 2.2314e+05],\n",
      "        [4.4278e+05, 1.6292e+04, 2.9580e+03, 2.9627e+04, 2.2152e+05, 1.6984e+05,\n",
      "         2.0960e+05, 2.3152e+05, 2.3984e+05, 1.8479e+05],\n",
      "        [2.3410e+05, 2.0284e+04, 5.7860e+03, 3.4782e+04, 1.2869e+04, 3.3525e+04,\n",
      "         3.1054e+05, 4.0976e+04, 5.9000e+04, 4.8019e+04],\n",
      "        [2.5426e+04, 9.8828e+04, 2.1154e+04, 1.7650e+05, 5.0525e+04, 1.2845e+05,\n",
      "         4.1147e+05, 3.3659e+05, 4.0550e+05, 3.9277e+05],\n",
      "        [2.8115e+05, 5.2029e+05, 7.8618e+04, 9.6196e+05, 8.9395e+04, 8.9976e+05,\n",
      "         5.1240e+05, 6.3220e+05, 7.5200e+05, 7.3752e+05],\n",
      "        [1.1858e+06, 7.0965e+05, 4.0956e+05, 1.0097e+06, 7.8751e+05, 1.0286e+06,\n",
      "         1.2400e+05, 1.6100e+05, 1.9800e+05, 1.4450e+05],\n",
      "        [1.4377e+06, 8.9901e+05, 7.4050e+05, 1.0575e+06, 1.4856e+06, 1.1575e+06,\n",
      "         1.0925e+06, 1.7532e+06, 1.7720e+06, 1.5482e+06],\n",
      "        [1.4377e+06, 1.7135e+05, 1.1072e+05, 2.3198e+05, 1.4856e+06, 2.7388e+05,\n",
      "         1.4371e+05, 1.2240e+05, 1.0940e+05, 1.4470e+05]], dtype=torch.float64)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pesticides_tensor.shape)\n",
    "print(fertilizers_tensor.shape)\n",
    "\n",
    "# TODO: Normalize inputs before concatenation\n",
    "\n",
    "\n",
    "pesticides_and_fertilizers = torch.cat((pesticides_tensor, fertilizers_tensor), dim=0)\n",
    "print(pesticides_and_fertilizers.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Training X data for 10 years: \",pesticides_and_fertilizers)\n",
    "print(\"\\n\")\n",
    "X_train_ten = pesticides_and_fertilizers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Create output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
      "       'Unit', 'Y1961', 'Y1962', 'Y1963', 'Y1964', 'Y1965', 'Y1966', 'Y1967',\n",
      "       'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972', 'Y1973', 'Y1974', 'Y1975',\n",
      "       'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983',\n",
      "       'Y1984', 'Y1985', 'Y1986', 'Y1987', 'Y1988', 'Y1989', 'Y1990', 'Y1991',\n",
      "       'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999',\n",
      "       'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007',\n",
      "       'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2014', 'Y2015',\n",
      "       'Y2016', 'Y2017', 'Y2018'],\n",
      "      dtype='object')\n",
      "      Area Code       Area  Item Code                              Item  \\\n",
      "1317         10  Australia        221               Almonds, with shell   \n",
      "1318         10  Australia        221               Almonds, with shell   \n",
      "1319         10  Australia        221               Almonds, with shell   \n",
      "1320         10  Australia        711  Anise, badian, fennel, coriander   \n",
      "1321         10  Australia        711  Anise, badian, fennel, coriander   \n",
      "...         ...        ...        ...                               ...   \n",
      "1606         10  Australia       1729                   Treenuts, Total   \n",
      "1607         10  Australia       1729                   Treenuts, Total   \n",
      "1608         10  Australia       1735                Vegetables Primary   \n",
      "1609         10  Australia       1735                Vegetables Primary   \n",
      "1610         10  Australia       1735                Vegetables Primary   \n",
      "\n",
      "      Element Code         Element    Unit     Y1961     Y1962     Y1963  ...  \\\n",
      "1317          5312  Area harvested      ha       NaN       NaN       NaN  ...   \n",
      "1318          5419           Yield   hg/ha       NaN       NaN       NaN  ...   \n",
      "1319          5510      Production  tonnes       NaN       NaN       NaN  ...   \n",
      "1320          5312  Area harvested      ha       NaN       NaN       NaN  ...   \n",
      "1321          5419           Yield   hg/ha       NaN       NaN       NaN  ...   \n",
      "...            ...             ...     ...       ...       ...       ...  ...   \n",
      "1606          5419           Yield   hg/ha   17925.0   15042.0   15856.0  ...   \n",
      "1607          5510      Production  tonnes     190.0     179.0     176.0  ...   \n",
      "1608          5312  Area harvested      ha   63571.0   63397.0   65291.0  ...   \n",
      "1609          5419           Yield   hg/ha  100846.0  103588.0  101085.0  ...   \n",
      "1610          5510      Production  tonnes  641089.0  656717.0  659995.0  ...   \n",
      "\n",
      "          Y2009      Y2010      Y2011      Y2012      Y2013      Y2014  \\\n",
      "1317    27981.0    29340.0    30390.0    28472.0    28586.0    28967.0   \n",
      "1318     6775.0    30675.0    11377.0    10925.0    19863.0    19325.0   \n",
      "1319    18957.0    90000.0    34576.0    31105.0    56779.0    55978.0   \n",
      "1320      710.0      684.0      914.0     1015.0     1040.0     1000.0   \n",
      "1321    13901.0    11853.0    11370.0    11488.0    11550.0    11570.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1606    12376.0    24996.0    12309.0    11661.0    17257.0    17692.0   \n",
      "1607    60694.0   130580.0    70926.0    65324.0    92450.0    94930.0   \n",
      "1608    66234.0    69695.0    74100.0    71471.0    66887.0    69262.0   \n",
      "1609   270772.0   259637.0   224916.0   253910.0   277885.0   238561.0   \n",
      "1610  1793425.0  1809529.0  1666625.0  1814715.0  1858687.0  1652335.0   \n",
      "\n",
      "          Y2015      Y2016      Y2017      Y2018  \n",
      "1317    31115.0    37000.0    38000.0    36940.0  \n",
      "1318    20354.0    19703.0    19835.0    18917.0  \n",
      "1319    63331.0    72902.0    75373.0    69880.0  \n",
      "1320     1011.0     1108.0     1130.0     1074.0  \n",
      "1321    11600.0    11673.0    11721.0    11769.0  \n",
      "...         ...        ...        ...        ...  \n",
      "1606    16017.0    17399.0    17430.0    16445.0  \n",
      "1607   106374.0   118977.0   125683.0   118104.0  \n",
      "1608    66917.0    68090.0    71918.0    70457.0  \n",
      "1609   264193.0   257780.0   245961.0   252789.0  \n",
      "1610  1767902.0  1755227.0  1768915.0  1781067.0  \n",
      "\n",
      "[294 rows x 65 columns]\n",
      "\n",
      "\n",
      "Test Y data:                                    Item      Y2017\n",
      "1319               Almonds, with shell    75373.0\n",
      "1322  Anise, badian, fennel, coriander     1324.0\n",
      "1325                            Apples   313730.0\n",
      "1328                          Apricots     5351.0\n",
      "1331                         Asparagus     7472.0\n",
      "...                                ...        ...\n",
      "1598          Oilcrops, Oil Equivalent  1888936.0\n",
      "1601                     Pulses, Total  4129481.0\n",
      "1604           Roots and Tubers, Total  1176669.0\n",
      "1607                   Treenuts, Total   125683.0\n",
      "1610                Vegetables Primary  1768915.0\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "\n",
      "\n",
      "Index(['Item', 'Y2017'], dtype='object')\n",
      "['Almonds, with shell' 'Anise, badian, fennel, coriander' 'Apples'\n",
      " 'Apricots' 'Asparagus' 'Avocados' 'Bananas' 'Barley' 'Beans, dry'\n",
      " 'Beans, green' 'Berries nes' 'Blueberries'\n",
      " 'Broad beans, horse beans, dry' 'Cabbages and other brassicas'\n",
      " 'Canary seed' 'Carrots and turnips' 'Cauliflowers and broccoli'\n",
      " 'Cherries' 'Chick peas' 'Chillies and peppers, green' 'Cotton lint'\n",
      " 'Cottonseed' 'Cow peas, dry' 'Cucumbers and gherkins' 'Currants'\n",
      " 'Fibre crops nes' 'Figs' 'Flax fibre and tow' 'Fruit, citrus nes'\n",
      " 'Fruit, stone nes' 'Fruit, tropical fresh nes'\n",
      " 'Grapefruit (inc. pomelos)' 'Grapes' 'Groundnuts, with shell' 'Hops'\n",
      " 'Kiwi fruit' 'Lemons and limes' 'Lentils' 'Lettuce and chicory' 'Linseed'\n",
      " 'Lupins' 'Maize' 'Maize, green' 'Mangoes, mangosteens, guavas'\n",
      " 'Melons, other (inc.cantaloupes)' 'Millet' 'Mushrooms and truffles'\n",
      " 'Mustard seed' 'Nuts nes' 'Oats' 'Olives' 'Onions, dry' 'Oranges'\n",
      " 'Papayas' 'Peaches and nectarines' 'Pears' 'Peas, dry' 'Peas, green'\n",
      " 'Persimmons' 'Pineapples' 'Pistachios' 'Plums and sloes' 'Potatoes'\n",
      " 'Pulses nes' 'Pumpkins, squash and gourds' 'Quinces' 'Rapeseed'\n",
      " 'Raspberries' 'Rice, paddy' 'Rye' 'Safflower seed' 'Seed cotton'\n",
      " 'Sorghum' 'Soybeans' 'Spinach' 'Strawberries' 'Sugar cane'\n",
      " 'Sunflower seed' 'Sweet potatoes'\n",
      " 'Tangerines, mandarins, clementines, satsumas' 'Tobacco, unmanufactured'\n",
      " 'Tomatoes' 'Triticale' 'Vegetables, fresh nes' 'Vetches'\n",
      " 'Walnuts, with shell' 'Watermelons' 'Wheat' 'Cereals (Rice Milled Eqv)'\n",
      " 'Cereals, Total' 'Citrus Fruit, Total' 'Coarse Grain, Total'\n",
      " 'Fibre Crops Primary' 'Fruit Primary' 'Oilcrops'\n",
      " 'Oilcrops, Cake Equivalent' 'Oilcrops, Oil Equivalent' 'Pulses, Total'\n",
      " 'Roots and Tubers, Total' 'Treenuts, Total' 'Vegetables Primary']\n",
      "Number of unique crops in 2017:  101\n",
      "Index(['Item', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013',\n",
      "       'Y2014', 'Y2015', 'Y2016'],\n",
      "      dtype='object')\n",
      "['Almonds, with shell' 'Anise, badian, fennel, coriander' 'Apples'\n",
      " 'Apricots' 'Asparagus' 'Avocados' 'Bananas' 'Barley' 'Beans, dry'\n",
      " 'Beans, green' 'Berries nes' 'Blueberries'\n",
      " 'Broad beans, horse beans, dry' 'Cabbages and other brassicas'\n",
      " 'Canary seed' 'Carrots and turnips' 'Cauliflowers and broccoli'\n",
      " 'Cherries' 'Chick peas' 'Chillies and peppers, green' 'Cotton lint'\n",
      " 'Cottonseed' 'Cow peas, dry' 'Cucumbers and gherkins' 'Currants'\n",
      " 'Fibre crops nes' 'Figs' 'Flax fibre and tow' 'Fruit, citrus nes'\n",
      " 'Fruit, stone nes' 'Fruit, tropical fresh nes'\n",
      " 'Grapefruit (inc. pomelos)' 'Grapes' 'Groundnuts, with shell' 'Hops'\n",
      " 'Kiwi fruit' 'Lemons and limes' 'Lentils' 'Lettuce and chicory' 'Linseed'\n",
      " 'Lupins' 'Maize' 'Maize, green' 'Mangoes, mangosteens, guavas'\n",
      " 'Melons, other (inc.cantaloupes)' 'Millet' 'Mushrooms and truffles'\n",
      " 'Mustard seed' 'Nuts nes' 'Oats' 'Olives' 'Onions, dry' 'Oranges'\n",
      " 'Papayas' 'Peaches and nectarines' 'Pears' 'Peas, dry' 'Peas, green'\n",
      " 'Persimmons' 'Pineapples' 'Pistachios' 'Plums and sloes' 'Potatoes'\n",
      " 'Pulses nes' 'Pumpkins, squash and gourds' 'Quinces' 'Rapeseed'\n",
      " 'Raspberries' 'Rice, paddy' 'Rye' 'Safflower seed' 'Seed cotton'\n",
      " 'Sorghum' 'Soybeans' 'Spinach' 'Strawberries' 'Sugar cane'\n",
      " 'Sunflower seed' 'Sweet potatoes'\n",
      " 'Tangerines, mandarins, clementines, satsumas' 'Tobacco, unmanufactured'\n",
      " 'Tomatoes' 'Triticale' 'Vegetables, fresh nes' 'Vetches'\n",
      " 'Walnuts, with shell' 'Watermelons' 'Wheat' 'Cereals (Rice Milled Eqv)'\n",
      " 'Cereals, Total' 'Citrus Fruit, Total' 'Coarse Grain, Total'\n",
      " 'Fibre Crops Primary' 'Fruit Primary' 'Oilcrops'\n",
      " 'Oilcrops, Cake Equivalent' 'Oilcrops, Oil Equivalent' 'Pulses, Total'\n",
      " 'Roots and Tubers, Total' 'Treenuts, Total' 'Vegetables Primary']\n",
      "\n",
      "\n",
      "Train Y data:                                    Item      Y2007      Y2008      Y2009  \\\n",
      "1319               Almonds, with shell    18024.0    65000.0    18957.0   \n",
      "1322  Anise, badian, fennel, coriander       51.0     2091.0      987.0   \n",
      "1325                            Apples   377980.0   265481.0   295134.0   \n",
      "1328                          Apricots    17327.0    17000.0    13673.0   \n",
      "1331                         Asparagus     5609.0     9779.0     6981.0   \n",
      "...                                ...        ...        ...        ...   \n",
      "1598          Oilcrops, Oil Equivalent   311986.0   553601.0   836928.0   \n",
      "1601                     Pulses, Total  1168635.0  1681825.0  1817218.0   \n",
      "1604           Roots and Tubers, Total  1261119.0  1447602.0  1220994.0   \n",
      "1607                   Treenuts, Total    60924.0   103690.0    60694.0   \n",
      "1610                Vegetables Primary  1746974.0  1703422.0  1793425.0   \n",
      "\n",
      "          Y2010      Y2011      Y2012      Y2013      Y2014      Y2015  \\\n",
      "1319    90000.0    34576.0    31105.0    56779.0    55978.0    63331.0   \n",
      "1322      810.0     1039.0     1166.0     1201.0     1157.0     1173.0   \n",
      "1325   264401.0   299778.0   289064.0   288878.0   266771.0   295196.0   \n",
      "1328    13175.0    13283.0    12186.0    11551.0     9238.0     9674.0   \n",
      "1331     8835.0    10276.0     9589.0     8396.0     8375.0     8288.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1598   869470.0  1152688.0  1647064.0  1869619.0  1709984.0  1503124.0   \n",
      "1601  2143709.0  2551800.0  2633541.0  2224400.0  2247300.0  1989200.0   \n",
      "1604  1327922.0  1185085.0  1350721.0  1341112.0  1246546.0  1215195.0   \n",
      "1607   130580.0    70926.0    65324.0    92450.0    94930.0   106374.0   \n",
      "1610  1809529.0  1666625.0  1814715.0  1858687.0  1652335.0  1767902.0   \n",
      "\n",
      "          Y2016  \n",
      "1319    72902.0  \n",
      "1322     1293.0  \n",
      "1325   308298.0  \n",
      "1328     8700.0  \n",
      "1331     7737.0  \n",
      "...         ...  \n",
      "1598  1239283.0  \n",
      "1601  2421811.0  \n",
      "1604  1200748.0  \n",
      "1607   118977.0  \n",
      "1610  1755227.0  \n",
      "\n",
      "[101 rows x 11 columns]\n",
      "\n",
      "\n",
      "Number of unique crops from 2007 to 2016 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(ProductionYield.columns)\n",
    "#%%\n",
    "ProductionYield.head\n",
    "#%%\n",
    "Australia = ProductionYield['Area']==\"Australia\"\n",
    "Production = ProductionYield['Element']==\"Production\"\n",
    "Australia_yield = ProductionYield[Australia]\n",
    "Australia_yield_production = Australia_yield[Production]\n",
    "print(ProductionYield[Australia])\n",
    "#%%\n",
    "# Get the yield data for the year 2017 only\n",
    "Australia_yield_2017 = Australia_yield_production.drop(['Area Code', 'Area', 'Item Code', 'Element Code','Element',\n",
    "       'Unit','Y1961', 'Y1962', 'Y1963', 'Y1964', 'Y1965', 'Y1966', 'Y1967', 'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972', 'Y1973', \n",
    "       'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986', 'Y1987',\n",
    "        'Y1988', 'Y1989', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', \n",
    "        'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2014', 'Y2015', \n",
    "        'Y2016', 'Y2018'], axis=1)\n",
    "print(\"\\n\")\n",
    "print(\"Test Y data: \",Australia_yield_2017)\n",
    "print(\"\\n\")\n",
    "print(Australia_yield_2017.columns)\n",
    "print(Australia_yield_2017['Item'].unique())\n",
    "print(\"Number of unique crops in 2017: \",len(Australia_yield_2017['Item'].unique()))\n",
    "\n",
    "Australia_yield_2007_to_2016 = Australia_yield_production.drop(['Area Code', 'Area', 'Item Code', 'Element Code','Element',\n",
    "       'Unit','Y1961', 'Y1962', 'Y1963', 'Y1964', 'Y1965', 'Y1966', 'Y1967', 'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972', 'Y1973', \n",
    "       'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986', 'Y1987',\n",
    "        'Y1988', 'Y1989', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', \n",
    "        'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2017','Y2018'], axis=1)\n",
    "print(Australia_yield_2007_to_2016.columns)\n",
    "print(Australia_yield_2007_to_2016['Item'].unique())\n",
    "print(\"\\n\")\n",
    "print(\"Train Y data: \",Australia_yield_2007_to_2016)\n",
    "print(\"\\n\")\n",
    "print(\"Number of unique crops from 2007 to 2016\",len(Australia_yield_2007_to_2016['Item'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Y2007      Y2008      Y2009      Y2010      Y2011      Y2012  \\\n",
      "1319    18024.0    65000.0    18957.0    90000.0    34576.0    31105.0   \n",
      "1322       51.0     2091.0      987.0      810.0     1039.0     1166.0   \n",
      "1325   377980.0   265481.0   295134.0   264401.0   299778.0   289064.0   \n",
      "1328    17327.0    17000.0    13673.0    13175.0    13283.0    12186.0   \n",
      "1331     5609.0     9779.0     6981.0     8835.0    10276.0     9589.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1598   311986.0   553601.0   836928.0   869470.0  1152688.0  1647064.0   \n",
      "1601  1168635.0  1681825.0  1817218.0  2143709.0  2551800.0  2633541.0   \n",
      "1604  1261119.0  1447602.0  1220994.0  1327922.0  1185085.0  1350721.0   \n",
      "1607    60924.0   103690.0    60694.0   130580.0    70926.0    65324.0   \n",
      "1610  1746974.0  1703422.0  1793425.0  1809529.0  1666625.0  1814715.0   \n",
      "\n",
      "          Y2013      Y2014      Y2015      Y2016  \n",
      "1319    56779.0    55978.0    63331.0    72902.0  \n",
      "1322     1201.0     1157.0     1173.0     1293.0  \n",
      "1325   288878.0   266771.0   295196.0   308298.0  \n",
      "1328    11551.0     9238.0     9674.0     8700.0  \n",
      "1331     8396.0     8375.0     8288.0     7737.0  \n",
      "...         ...        ...        ...        ...  \n",
      "1598  1869619.0  1709984.0  1503124.0  1239283.0  \n",
      "1601  2224400.0  2247300.0  1989200.0  2421811.0  \n",
      "1604  1341112.0  1246546.0  1215195.0  1200748.0  \n",
      "1607    92450.0    94930.0   106374.0   118977.0  \n",
      "1610  1858687.0  1652335.0  1767902.0  1755227.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "Shape:  torch.Size([101, 10])\n",
      "\t Yield tensor tensor([[1.8024e+04, 6.5000e+04, 1.8957e+04,  ..., 5.5978e+04, 6.3331e+04,\n",
      "         7.2902e+04],\n",
      "        [5.1000e+01, 2.0910e+03, 9.8700e+02,  ..., 1.1570e+03, 1.1730e+03,\n",
      "         1.2930e+03],\n",
      "        [3.7798e+05, 2.6548e+05, 2.9513e+05,  ..., 2.6677e+05, 2.9520e+05,\n",
      "         3.0830e+05],\n",
      "        ...,\n",
      "        [1.2611e+06, 1.4476e+06, 1.2210e+06,  ..., 1.2465e+06, 1.2152e+06,\n",
      "         1.2007e+06],\n",
      "        [6.0924e+04, 1.0369e+05, 6.0694e+04,  ..., 9.4930e+04, 1.0637e+05,\n",
      "         1.1898e+05],\n",
      "        [1.7470e+06, 1.7034e+06, 1.7934e+06,  ..., 1.6523e+06, 1.7679e+06,\n",
      "         1.7552e+06]], dtype=torch.float64)\n",
      "torch.Size([22, 10])\n",
      "torch.Size([101, 10])\n"
     ]
    }
   ],
   "source": [
    "yield_without_Item = Australia_yield_2007_to_2016.copy().drop(['Item'],axis=1)\n",
    "\n",
    "print(yield_without_Item)\n",
    "yield_tensor = torch.from_numpy(yield_without_Item.values)\n",
    "print(\"Shape: \", yield_tensor.shape)\n",
    "print(\"\\t Yield tensor\", yield_tensor)\n",
    "Y_train_ten = yield_tensor\n",
    "\n",
    "print(X_train_ten.shape)\n",
    "print(Y_train_ten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Item     Y2017\n",
      "1325  Apples  313730.0\n",
      "Index(['Y2017'], dtype='object')\n",
      "602      35411.0\n",
      "607     151418.0\n",
      "613     146420.0\n",
      "618          NaN\n",
      "624          NaN\n",
      "634     962951.0\n",
      "639          NaN\n",
      "644     287906.0\n",
      "649          NaN\n",
      "654     358631.0\n",
      "667          NaN\n",
      "672     140339.0\n",
      "677      25094.0\n",
      "682          NaN\n",
      "691     700323.0\n",
      "695     176067.0\n",
      "701    1678298.0\n",
      "706     128677.2\n",
      "Name: Y2017, dtype: float64\n",
      "Input training data \n",
      "          Y2016\n",
      "602    39761.0\n",
      "607   165970.0\n",
      "613   172581.0\n",
      "618        NaN\n",
      "624        NaN\n",
      "634  1114790.0\n",
      "639        NaN\n",
      "644   211449.0\n",
      "649        NaN\n",
      "654   261487.0\n",
      "667        NaN\n",
      "672   184787.0\n",
      "677    48019.0\n",
      "682        NaN\n",
      "691   737519.0\n",
      "695   144503.0\n",
      "701  1548247.0\n",
      "706   144700.0\n",
      "\n",
      "\n",
      "Input testing data \n",
      " 602      35411.0\n",
      "607     151418.0\n",
      "613     146420.0\n",
      "618          NaN\n",
      "624          NaN\n",
      "634     962951.0\n",
      "639          NaN\n",
      "644     287906.0\n",
      "649          NaN\n",
      "654     358631.0\n",
      "667          NaN\n",
      "672     140339.0\n",
      "677      25094.0\n",
      "682          NaN\n",
      "691     700323.0\n",
      "695     176067.0\n",
      "701    1678298.0\n",
      "706     128677.2\n",
      "Name: Y2017, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Get the apple yield for 2017 Australia\n",
    "Apples = Australia_yield_2017['Item']==\"Apples\"\n",
    "Australia_yield_2017_apples=Australia_yield_2017[Apples]\n",
    "print(Australia_yield_2017_apples)\n",
    "# %%\n",
    "# Use 2016 data for training and 2017 data for testing\n",
    "X = Australia_Fertilizers_Products_Agricultural.drop(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
    "       'Unit','Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007', 'Y2008',\n",
    "       'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2015','Y2014'],axis=1)\n",
    "# 2017 for testing\n",
    "X_test=X['Y2017']\n",
    "print(X_test.to_frame().columns)\n",
    "print(X_test)\n",
    "#%%\n",
    "# Remove 2017 data from the train set\n",
    "X_train=X.drop(['Y2017'],axis=1)\n",
    "print(\"Input training data \\n\",X_train)\n",
    "print(\"\\n\")\n",
    "print(\"Input testing data \\n\",X_test)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X --> \n",
      " tensor([[3.2446e+04, 4.2935e+04, 3.8066e+04, 4.2169e+04, 4.7633e+04, 4.8688e+04,\n",
      "         4.5177e+04, 4.9857e+04, 5.0922e+04, 6.3416e+04],\n",
      "        [7.2630e+03, 9.6109e+03, 8.5209e+03, 9.4395e+03, 1.0662e+04, 1.0899e+04,\n",
      "         1.0113e+04, 1.1160e+04, 1.1399e+04, 1.4196e+04],\n",
      "        [2.2404e+04, 2.9647e+04, 2.6284e+04, 2.9118e+04, 3.2890e+04, 3.3619e+04,\n",
      "         3.1195e+04, 3.4426e+04, 3.5161e+04, 4.3789e+04],\n",
      "        [2.3249e+03, 3.0765e+03, 2.7276e+03, 3.0216e+03, 3.4131e+03, 3.4887e+03,\n",
      "         3.2371e+03, 3.5725e+03, 3.6487e+03, 4.5441e+03],\n",
      "        [4.5447e+02, 6.0139e+02, 5.3318e+02, 5.9066e+02, 6.6719e+02, 6.8197e+02,\n",
      "         6.3279e+02, 6.9835e+02, 7.1325e+02, 8.8827e+02],\n",
      "        [4.5447e+02, 6.0139e+02, 5.3318e+02, 5.9066e+02, 6.6719e+02, 6.8197e+02,\n",
      "         6.3279e+02, 6.9835e+02, 7.1325e+02, 8.8827e+02],\n",
      "        [3.0365e+05, 1.6086e+05,        nan, 1.6086e+05, 4.7329e+04, 1.5680e+05,\n",
      "         1.3463e+05, 1.3892e+05, 1.9200e+05, 1.7258e+05],\n",
      "        [2.0392e+04, 2.9583e+05, 7.4000e+01, 5.9159e+05, 2.6952e+05, 6.4043e+05,\n",
      "         1.4296e+05, 3.7954e+05, 4.9362e+05, 4.8665e+05],\n",
      "        [7.3190e+04, 6.1536e+05, 2.0840e+05, 1.0223e+06, 4.9172e+05, 1.1241e+06,\n",
      "         1.5129e+05, 6.2017e+05, 7.9523e+05, 8.0072e+05],\n",
      "        [1.2599e+05, 7.7861e+05, 4.1672e+05, 1.1405e+06, 7.1392e+05, 9.8775e+05,\n",
      "         1.5962e+05, 8.6079e+05, 1.0969e+06, 1.1148e+06],\n",
      "        [1.7879e+05, 6.4986e+05, 4.1037e+04, 1.2587e+06, 1.1699e+05, 8.5143e+05,\n",
      "         1.6795e+05, 6.1150e+05, 7.0043e+05, 6.6312e+05],\n",
      "        [2.3158e+05, 3.2902e+05, 2.1622e+04, 6.3643e+05, 7.9886e+04, 7.1511e+05,\n",
      "         1.7628e+05, 3.6221e+05, 3.0400e+05, 2.1145e+05],\n",
      "        [2.8438e+05, 8.1850e+03, 2.2080e+03, 1.4162e+04, 4.2783e+04, 5.7880e+05,\n",
      "         1.8461e+05, 3.5574e+05, 3.5850e+05, 2.3647e+05],\n",
      "        [3.3718e+05, 1.0243e+04, 1.1690e+03, 1.9317e+04, 2.1696e+04, 4.4248e+05,\n",
      "         1.9294e+05, 3.4928e+05, 4.1300e+05, 2.6149e+05],\n",
      "        [3.8998e+05, 1.2301e+04, 1.3000e+02, 2.4472e+04, 6.0900e+02, 3.0616e+05,\n",
      "         2.0127e+05, 2.9040e+05, 3.2642e+05, 2.2314e+05],\n",
      "        [4.4278e+05, 1.6292e+04, 2.9580e+03, 2.9627e+04, 2.2152e+05, 1.6984e+05,\n",
      "         2.0960e+05, 2.3152e+05, 2.3984e+05, 1.8479e+05],\n",
      "        [2.3410e+05, 2.0284e+04, 5.7860e+03, 3.4782e+04, 1.2869e+04, 3.3525e+04,\n",
      "         3.1054e+05, 4.0976e+04, 5.9000e+04, 4.8019e+04],\n",
      "        [2.5426e+04, 9.8828e+04, 2.1154e+04, 1.7650e+05, 5.0525e+04, 1.2845e+05,\n",
      "         4.1147e+05, 3.3659e+05, 4.0550e+05, 3.9277e+05],\n",
      "        [2.8115e+05, 5.2029e+05, 7.8618e+04, 9.6196e+05, 8.9395e+04, 8.9976e+05,\n",
      "         5.1240e+05, 6.3220e+05, 7.5200e+05, 7.3752e+05],\n",
      "        [1.1858e+06, 7.0965e+05, 4.0956e+05, 1.0097e+06, 7.8751e+05, 1.0286e+06,\n",
      "         1.2400e+05, 1.6100e+05, 1.9800e+05, 1.4450e+05],\n",
      "        [1.4377e+06, 8.9901e+05, 7.4050e+05, 1.0575e+06, 1.4856e+06, 1.1575e+06,\n",
      "         1.0925e+06, 1.7532e+06, 1.7720e+06, 1.5482e+06],\n",
      "        [1.4377e+06, 1.7135e+05, 1.1072e+05, 2.3198e+05, 1.4856e+06, 2.7388e+05,\n",
      "         1.4371e+05, 1.2240e+05, 1.0940e+05, 1.4470e+05]], dtype=torch.float64)\n",
      "\n",
      "\n",
      "torch.Size([22, 10])\n",
      "Y --> \n",
      " tensor([[1.8024e+04, 6.5000e+04, 1.8957e+04,  ..., 5.5978e+04, 6.3331e+04,\n",
      "         7.2902e+04],\n",
      "        [5.1000e+01, 2.0910e+03, 9.8700e+02,  ..., 1.1570e+03, 1.1730e+03,\n",
      "         1.2930e+03],\n",
      "        [3.7798e+05, 2.6548e+05, 2.9513e+05,  ..., 2.6677e+05, 2.9520e+05,\n",
      "         3.0830e+05],\n",
      "        ...,\n",
      "        [1.2611e+06, 1.4476e+06, 1.2210e+06,  ..., 1.2465e+06, 1.2152e+06,\n",
      "         1.2007e+06],\n",
      "        [6.0924e+04, 1.0369e+05, 6.0694e+04,  ..., 9.4930e+04, 1.0637e+05,\n",
      "         1.1898e+05],\n",
      "        [1.7470e+06, 1.7034e+06, 1.7934e+06,  ..., 1.6523e+06, 1.7679e+06,\n",
      "         1.7552e+06]], dtype=torch.float64)\n",
      "\n",
      "\n",
      "torch.Size([101, 10])\n"
     ]
    }
   ],
   "source": [
    "# Y = Australia_yield_production.drop(['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element',\n",
    "#        'Unit', 'Y1961', 'Y1962', 'Y1963', 'Y1964', 'Y1965', 'Y1966', 'Y1967',\n",
    "#        'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972', 'Y1973', 'Y1974', 'Y1975',\n",
    "#        'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983',\n",
    "#        'Y1984', 'Y1985', 'Y1986', 'Y1987', 'Y1988', 'Y1989', 'Y1990', 'Y1991',\n",
    "#        'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999',\n",
    "#        'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007',\n",
    "#        'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013', 'Y2014', 'Y2017', 'Y2018'], axis=1)\n",
    "# Y_train = Y[Apples]\n",
    "# # 2017 for testing\n",
    "# Y_test = Australia_yield_2017_apples['Y2017']\n",
    "# print(\"Output training \\n\",Y_train['Y2016'])\n",
    "# print(\"\\n\")\n",
    "# print(\"Output testing \\n\",Y_test)\n",
    "# # %%\n",
    "# X_train_dl = DataLoader(X_train[:1])\n",
    "# print(len(X_train_dl.dataset))\n",
    "# Y_train_dl = DataLoader(Y_train)\n",
    "# print(len(Y_train_dl.dataset))\n",
    "# %%\n",
    "# TODO: Refactor\n",
    "# x = torch.Tensor(X_train.dropna().to_numpy())\n",
    "# print(\"Apple yield for 2016  \\n\", Y_train['Y2016'])\n",
    "# print(\"\\n\")\n",
    "# y = torch.mean(torch.Tensor(Y_train['Y2016'].to_numpy()))\n",
    "x = X_train_ten\n",
    "y = Y_train_ten\n",
    "print(\"X --> \\n\",x)\n",
    "print(\"\\n\")\n",
    "print(x.shape)\n",
    "print(\"Y --> \\n\",y)\n",
    "print(\"\\n\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "       def __init__(self, D_in, H1, H2, H3, D_out):\n",
    "              super(NeuralNet, self).__init__()\n",
    "              self.linear1 = nn.Linear(D_in, H1)\n",
    "              self.linear2 = nn.Linear(H1, H2)\n",
    "              self.linear3 = nn.Linear(H2, H3)\n",
    "              self.linear4 = nn.Linear(H3, D_out)\n",
    "       def forward(self, x):\n",
    "              print(\"Forward pass\")\n",
    "              y_pred = self.linear1(x)\n",
    "#               print(y_pred)\n",
    "              y_pred = self.linear2(y_pred)\n",
    "#               print(y_pred)\n",
    "              y_pred = self.linear3(y_pred)\n",
    "#               print(y_pred)\n",
    "              y_pred = self.linear4(y_pred)\n",
    "#               print(y_pred)\n",
    "              return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1, H2, H3 = 500, 1000, 200\n",
    "D_in, D_out = 22, 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "Normalization of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 10])\n",
      "Normal  tensor([[-8.0742e-01,  1.2008e+00,  1.0855e-01, -4.2157e-01,  1.6124e+00,\n",
      "         -3.5102e-01,  1.6422e+00,  2.3086e-01, -1.1768e+00, -9.8418e-01],\n",
      "        [ 1.3801e-01, -6.3044e-01,  4.3968e-01,  1.0923e+00,  2.4473e-01,\n",
      "          9.5094e-01, -1.3664e+00, -9.1360e-01,  1.1452e+00, -9.3431e-01],\n",
      "        [-9.3493e-01, -1.4570e+00,  9.2529e-01, -7.5493e-01, -5.2806e-01,\n",
      "         -1.8451e+00,  6.2360e-01, -2.3548e+00, -1.2384e+00, -1.5792e+00],\n",
      "        [-2.3441e-01,  2.0920e-01,  1.2764e-01, -1.5606e+00, -7.3030e-01,\n",
      "         -1.6016e-01, -1.0527e+00,  9.0262e-01, -7.2090e-01,  1.7800e-01],\n",
      "        [-8.2002e-01, -3.1784e-01, -4.5260e-02,  6.9169e-01, -1.1845e+00,\n",
      "          3.4885e-01, -2.6260e+00,  1.4842e+00,  2.4613e+00, -1.4173e-03],\n",
      "        [ 4.0608e-01, -8.1333e-01, -1.2193e-01, -3.6468e-01,  2.7786e+00,\n",
      "          2.9994e-01,  1.1777e+00, -1.0104e+00,  2.0675e-01,  4.4101e-01],\n",
      "        [ 2.8751e+00,  4.2748e-01, -5.7367e-01,  6.9164e-01, -3.7816e-01,\n",
      "         -1.1452e+00, -1.7155e-01, -7.3906e-01, -8.1857e-01, -1.3090e-01],\n",
      "        [-7.4715e-01, -1.0838e+00,  8.8823e-01, -1.9291e+00, -1.2603e+00,\n",
      "          7.5107e-01, -1.6132e+00,  7.9421e-01, -9.6048e-01,  1.8557e-01],\n",
      "        [ 5.7217e-01, -2.5630e-01, -1.0373e+00,  9.1366e-01,  1.7175e-01,\n",
      "          6.1340e-01,  1.0816e-01, -1.0130e+00, -2.5380e-01,  1.0955e+00],\n",
      "        [ 5.6980e-01, -6.2561e-01, -1.4423e+00,  4.9491e-01, -1.2016e-01,\n",
      "          4.2932e-01,  2.5774e-01, -3.6188e-01, -1.8866e+00,  2.9298e-01],\n",
      "        [-3.2644e-01, -1.2553e+00, -5.6453e-01,  5.5958e-01,  1.6065e-01,\n",
      "         -4.5535e-01, -8.1481e-02,  1.5012e+00, -1.7409e-01, -2.6382e-01],\n",
      "        [-7.4317e-01, -7.2446e-01, -1.4672e+00,  6.4123e-01,  9.9994e-01,\n",
      "         -3.3417e-01,  1.6348e-01, -9.4453e-01,  9.9077e-02,  1.5779e+00],\n",
      "        [-2.6705e-01, -3.0342e-01,  2.6457e-01, -1.2854e+00,  7.3875e-01,\n",
      "          5.1317e-01,  2.5849e-03,  9.3899e-01, -7.7236e-01,  9.8452e-01],\n",
      "        [ 1.4563e+00, -9.7481e-01, -5.5420e-01, -7.1552e-01,  2.8237e-01,\n",
      "          6.2749e-01,  8.9946e-01, -1.4033e+00,  1.0137e+00,  1.2426e+00],\n",
      "        [-6.9546e-01, -4.5240e-01,  2.5272e-01, -1.4671e+00, -1.4358e+00,\n",
      "          4.5576e-01, -2.9694e-01, -4.3443e-02,  6.9445e-01, -2.1604e+00],\n",
      "        [-4.9888e-01, -5.2655e-01, -1.8306e-02,  6.5900e-01, -9.5556e-01,\n",
      "          4.3345e-01, -1.2271e+00,  5.4013e-01, -4.9784e-01, -2.9371e-01],\n",
      "        [ 1.8826e-01, -6.1062e-01,  2.1583e+00, -1.3657e+00, -2.1042e-01,\n",
      "         -3.2486e-01,  1.4876e+00, -4.7856e-02,  1.7019e+00, -1.8628e-01],\n",
      "        [-7.5126e-01, -4.0946e-01, -7.2211e-01,  3.6262e-01, -3.3697e-01,\n",
      "         -1.7707e-01,  1.2913e+00, -2.0507e+00,  8.8183e-01, -1.0857e+00],\n",
      "        [ 9.0760e-01,  1.0576e-01,  1.8844e+00,  1.7323e+00, -7.0711e-01,\n",
      "         -1.0785e+00, -4.9313e-01,  1.2398e+00, -1.0412e-01, -3.2777e-03],\n",
      "        [-6.4322e-01,  4.0814e-02,  4.7032e-01,  1.1604e+00,  1.1637e-01,\n",
      "         -6.2252e-01,  1.5875e+00,  6.4894e-01,  5.2870e-01,  1.4635e-01],\n",
      "        [ 1.0030e+00,  4.2070e-01, -3.9510e-02, -1.2440e+00, -9.1030e-01,\n",
      "         -5.1005e-01,  3.1632e+00, -8.1081e-01,  5.8030e-01,  1.1918e+00],\n",
      "        [ 1.0135e+00,  3.1497e-01, -5.1816e-01, -1.0931e+00, -8.6458e-01,\n",
      "          1.1256e-01,  2.1923e+00, -3.0768e-01,  9.0016e-02,  7.2527e-01]],\n",
      "       dtype=torch.float64)\n",
      "Rescaled y values:  tensor([[-0.5160, -1.6859, -0.2202,  ...,  1.0180, -1.5577,  0.3261],\n",
      "        [-1.2978, -0.1976, -0.7967,  ..., -1.1588, -0.6530, -1.2408],\n",
      "        [-1.7227, -0.4260, -0.2629,  ..., -0.6517, -0.9727,  0.7337],\n",
      "        ...,\n",
      "        [-0.5350,  0.3556, -2.4017,  ..., -0.0800,  0.3973,  0.1575],\n",
      "        [ 1.0756, -0.6810,  0.7710,  ...,  0.5709, -1.0821, -1.9882],\n",
      "        [-0.9076, -1.2679,  2.3238,  ..., -1.7921, -0.9416, -0.5856]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.Tensor(x.float())\n",
    "x_data = (x - x.mean())/(x.max() - x.min())\n",
    "test = torch.Tensor([[0,4,5]])\n",
    "# x_tensor_reshaped = x_tensor.reshape(10,22)\n",
    "# print(x_tensor_reshaped)\n",
    "\n",
    "# mean = torch.mean(x_tensor_reshaped, 0, True)\n",
    "# maximum = torch.max(x_tensor_reshaped, 0, True).values\n",
    "# minimum = torch.min(x_tensor_reshaped, 0, True).values\n",
    "\n",
    "# print(\"Mean \", torch.mean(x_tensor_reshaped, 0, True).shape)\n",
    "# print(\"Max \", torch.max(x_tensor_reshaped, 0, True).values.shape)\n",
    "# print(\"Min \", torch.min(x_tensor_reshaped, 0, True).values.shape)\n",
    "print(x.shape)\n",
    "x_tensor_normalized = x.normal_()\n",
    "print(\"Normal \", x_tensor_normalized)\n",
    "\n",
    "\n",
    "# print(\"In process: \", x_tensor_reshaped/100000)\n",
    "# x_data = (x_tensor_reshaped - mean/(maximum - minimum))\n",
    "# # x_data = x_tensor_reshaped/100000\n",
    "# print(\"Processed data: \", x_data)\n",
    "#%%\n",
    "# Rescale the output to match the range of the input\n",
    "y_data = (y.normal_())\n",
    "print(\"Rescaled y values: \",y_data)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = NeuralNet(D_in, H1, H2, H3, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (22x10 and 22x500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-93112d01b5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-bfe2a2c0ecda>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Forward pass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#               print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (22x10 and 22x500)"
     ]
    }
   ],
   "source": [
    "losses1 = []\n",
    "#%%\n",
    "for t in range(50):\n",
    "       y_pred = model1(x)\n",
    "       loss = loss_fn(y_pred, y)\n",
    "       print(t, loss.item())\n",
    "       losses1.append(loss.item())\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()       \n",
    "#%%\n",
    "# BEST \n",
    "# model2 = NeuralNet(D_in, H1, H2, H3, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-31333f97ebed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-22e419f882af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m        \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "       y_pred=model2(x_data)\n",
    "       print(torch.mean(y_pred))\n",
    "       loss = loss_fn(y_pred, y_data)\n",
    "       print(t, loss.item())\n",
    "       losses2.append(loss.item())\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss  --> \n",
      " tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean loss  --> \\n\", torch.mean(torch.Tensor(losses2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, predicted, actual, threshold_percentage):\n",
    "    num_items = len(actual)\n",
    "    print(\"Length: \",num_items)\n",
    "    X = predicted.view(num_items)\n",
    "    print(X)\n",
    "    print(X.shape)\n",
    "    Y = actual.view(num_items)\n",
    "    print(Y)\n",
    "    print(Y.shape)\n",
    "    num_correct = torch.sum(torch.abs(X-Y)<torch.abs(threshold_percentage*Y))\n",
    "    print(f\"No of correct predictions: {num_correct}\")\n",
    "    accuracy = (num_correct.item()*100.0/num_items)\n",
    "    print(f\"{accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.0742e-01,  1.2008e+00,  1.0855e-01, -4.2157e-01,  1.6124e+00,\n",
      "         -3.5102e-01,  1.6422e+00,  2.3086e-01, -1.1768e+00, -9.8418e-01,\n",
      "          1.3801e-01, -6.3044e-01,  4.3968e-01,  1.0923e+00,  2.4473e-01,\n",
      "          9.5094e-01, -1.3664e+00, -9.1360e-01,  1.1452e+00, -9.3431e-01,\n",
      "         -9.3493e-01, -1.4570e+00,  9.2529e-01, -7.5493e-01, -5.2806e-01,\n",
      "         -1.8451e+00,  6.2360e-01, -2.3548e+00, -1.2384e+00, -1.5792e+00,\n",
      "         -2.3441e-01,  2.0920e-01,  1.2764e-01, -1.5606e+00, -7.3030e-01,\n",
      "         -1.6016e-01, -1.0527e+00,  9.0262e-01, -7.2090e-01,  1.7800e-01,\n",
      "         -8.2002e-01, -3.1784e-01, -4.5260e-02,  6.9169e-01, -1.1845e+00,\n",
      "          3.4885e-01, -2.6260e+00,  1.4842e+00,  2.4613e+00, -1.4173e-03,\n",
      "          4.0608e-01, -8.1333e-01, -1.2193e-01, -3.6468e-01,  2.7786e+00,\n",
      "          2.9994e-01,  1.1777e+00, -1.0104e+00,  2.0675e-01,  4.4101e-01,\n",
      "          2.8751e+00,  4.2748e-01, -5.7367e-01,  6.9164e-01, -3.7816e-01,\n",
      "         -1.1452e+00, -1.7155e-01, -7.3906e-01, -8.1857e-01, -1.3090e-01,\n",
      "         -7.4715e-01, -1.0838e+00,  8.8823e-01, -1.9291e+00, -1.2603e+00,\n",
      "          7.5107e-01, -1.6132e+00,  7.9421e-01, -9.6048e-01,  1.8557e-01,\n",
      "          5.7217e-01, -2.5630e-01, -1.0373e+00,  9.1366e-01,  1.7175e-01,\n",
      "          6.1340e-01,  1.0816e-01, -1.0130e+00, -2.5380e-01,  1.0955e+00,\n",
      "          5.6980e-01, -6.2561e-01, -1.4423e+00,  4.9491e-01, -1.2016e-01,\n",
      "          4.2932e-01,  2.5774e-01, -3.6188e-01, -1.8866e+00,  2.9298e-01,\n",
      "         -3.2644e-01, -1.2553e+00, -5.6453e-01,  5.5958e-01,  1.6065e-01,\n",
      "         -4.5535e-01, -8.1481e-02,  1.5012e+00, -1.7409e-01, -2.6382e-01,\n",
      "         -7.4317e-01, -7.2446e-01, -1.4672e+00,  6.4123e-01,  9.9994e-01,\n",
      "         -3.3417e-01,  1.6348e-01, -9.4453e-01,  9.9077e-02,  1.5779e+00,\n",
      "         -2.6705e-01, -3.0342e-01,  2.6457e-01, -1.2854e+00,  7.3875e-01,\n",
      "          5.1317e-01,  2.5849e-03,  9.3899e-01, -7.7236e-01,  9.8452e-01,\n",
      "          1.4563e+00, -9.7481e-01, -5.5420e-01, -7.1552e-01,  2.8237e-01,\n",
      "          6.2749e-01,  8.9946e-01, -1.4033e+00,  1.0137e+00,  1.2426e+00,\n",
      "         -6.9546e-01, -4.5240e-01,  2.5272e-01, -1.4671e+00, -1.4358e+00,\n",
      "          4.5576e-01, -2.9694e-01, -4.3443e-02,  6.9445e-01, -2.1604e+00,\n",
      "         -4.9888e-01, -5.2655e-01, -1.8306e-02,  6.5900e-01, -9.5556e-01,\n",
      "          4.3345e-01, -1.2271e+00,  5.4013e-01, -4.9784e-01, -2.9371e-01,\n",
      "          1.8826e-01, -6.1062e-01,  2.1583e+00, -1.3657e+00, -2.1042e-01,\n",
      "         -3.2486e-01,  1.4876e+00, -4.7856e-02,  1.7019e+00, -1.8628e-01,\n",
      "         -7.5126e-01, -4.0946e-01, -7.2211e-01,  3.6262e-01, -3.3697e-01,\n",
      "         -1.7707e-01,  1.2913e+00, -2.0507e+00,  8.8183e-01, -1.0857e+00,\n",
      "          9.0760e-01,  1.0576e-01,  1.8844e+00,  1.7323e+00, -7.0711e-01,\n",
      "         -1.0785e+00, -4.9313e-01,  1.2398e+00, -1.0412e-01, -3.2777e-03,\n",
      "         -6.4322e-01,  4.0814e-02,  4.7032e-01,  1.1604e+00,  1.1637e-01,\n",
      "         -6.2252e-01,  1.5875e+00,  6.4894e-01,  5.2870e-01,  1.4635e-01,\n",
      "          1.0030e+00,  4.2070e-01, -3.9510e-02, -1.2440e+00, -9.1030e-01,\n",
      "         -5.1005e-01,  3.1632e+00, -8.1081e-01,  5.8030e-01,  1.1918e+00,\n",
      "          1.0135e+00,  3.1497e-01, -5.1816e-01, -1.0931e+00, -8.6458e-01,\n",
      "          1.1256e-01,  2.1923e+00, -3.0768e-01,  9.0016e-02,  7.2527e-01]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1, 220])\n",
      "tensor([[-0.5160, -1.6859, -0.2202,  ..., -1.7921, -0.9416, -0.5856]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1, 1010])\n",
      "Training loop \n",
      "\n",
      "Input  tensor([[-8.0742e-01,  1.2008e+00,  1.0855e-01, -4.2157e-01,  1.6124e+00,\n",
      "         -3.5102e-01,  1.6422e+00,  2.3086e-01, -1.1768e+00, -9.8418e-01,\n",
      "          1.3801e-01, -6.3044e-01,  4.3968e-01,  1.0923e+00,  2.4473e-01,\n",
      "          9.5094e-01, -1.3664e+00, -9.1360e-01,  1.1452e+00, -9.3431e-01,\n",
      "         -9.3493e-01, -1.4570e+00,  9.2529e-01, -7.5493e-01, -5.2806e-01,\n",
      "         -1.8451e+00,  6.2360e-01, -2.3548e+00, -1.2384e+00, -1.5792e+00,\n",
      "         -2.3441e-01,  2.0920e-01,  1.2764e-01, -1.5606e+00, -7.3030e-01,\n",
      "         -1.6016e-01, -1.0527e+00,  9.0262e-01, -7.2090e-01,  1.7800e-01,\n",
      "         -8.2002e-01, -3.1784e-01, -4.5260e-02,  6.9169e-01, -1.1845e+00,\n",
      "          3.4885e-01, -2.6260e+00,  1.4842e+00,  2.4613e+00, -1.4173e-03,\n",
      "          4.0608e-01, -8.1333e-01, -1.2193e-01, -3.6468e-01,  2.7786e+00,\n",
      "          2.9994e-01,  1.1777e+00, -1.0104e+00,  2.0675e-01,  4.4101e-01,\n",
      "          2.8751e+00,  4.2748e-01, -5.7367e-01,  6.9164e-01, -3.7816e-01,\n",
      "         -1.1452e+00, -1.7155e-01, -7.3906e-01, -8.1857e-01, -1.3090e-01,\n",
      "         -7.4715e-01, -1.0838e+00,  8.8823e-01, -1.9291e+00, -1.2603e+00,\n",
      "          7.5107e-01, -1.6132e+00,  7.9421e-01, -9.6048e-01,  1.8557e-01,\n",
      "          5.7217e-01, -2.5630e-01, -1.0373e+00,  9.1366e-01,  1.7175e-01,\n",
      "          6.1340e-01,  1.0816e-01, -1.0130e+00, -2.5380e-01,  1.0955e+00,\n",
      "          5.6980e-01, -6.2561e-01, -1.4423e+00,  4.9491e-01, -1.2016e-01,\n",
      "          4.2932e-01,  2.5774e-01, -3.6188e-01, -1.8866e+00,  2.9298e-01,\n",
      "         -3.2644e-01, -1.2553e+00, -5.6453e-01,  5.5958e-01,  1.6065e-01,\n",
      "         -4.5535e-01, -8.1481e-02,  1.5012e+00, -1.7409e-01, -2.6382e-01,\n",
      "         -7.4317e-01, -7.2446e-01, -1.4672e+00,  6.4123e-01,  9.9994e-01,\n",
      "         -3.3417e-01,  1.6348e-01, -9.4453e-01,  9.9077e-02,  1.5779e+00,\n",
      "         -2.6705e-01, -3.0342e-01,  2.6457e-01, -1.2854e+00,  7.3875e-01,\n",
      "          5.1317e-01,  2.5849e-03,  9.3899e-01, -7.7236e-01,  9.8452e-01,\n",
      "          1.4563e+00, -9.7481e-01, -5.5420e-01, -7.1552e-01,  2.8237e-01,\n",
      "          6.2749e-01,  8.9946e-01, -1.4033e+00,  1.0137e+00,  1.2426e+00,\n",
      "         -6.9546e-01, -4.5240e-01,  2.5272e-01, -1.4671e+00, -1.4358e+00,\n",
      "          4.5576e-01, -2.9694e-01, -4.3443e-02,  6.9445e-01, -2.1604e+00,\n",
      "         -4.9888e-01, -5.2655e-01, -1.8306e-02,  6.5900e-01, -9.5556e-01,\n",
      "          4.3345e-01, -1.2271e+00,  5.4013e-01, -4.9784e-01, -2.9371e-01,\n",
      "          1.8826e-01, -6.1062e-01,  2.1583e+00, -1.3657e+00, -2.1042e-01,\n",
      "         -3.2486e-01,  1.4876e+00, -4.7856e-02,  1.7019e+00, -1.8628e-01,\n",
      "         -7.5126e-01, -4.0946e-01, -7.2211e-01,  3.6262e-01, -3.3697e-01,\n",
      "         -1.7707e-01,  1.2913e+00, -2.0507e+00,  8.8183e-01, -1.0857e+00,\n",
      "          9.0760e-01,  1.0576e-01,  1.8844e+00,  1.7323e+00, -7.0711e-01,\n",
      "         -1.0785e+00, -4.9313e-01,  1.2398e+00, -1.0412e-01, -3.2777e-03,\n",
      "         -6.4322e-01,  4.0814e-02,  4.7032e-01,  1.1604e+00,  1.1637e-01,\n",
      "         -6.2252e-01,  1.5875e+00,  6.4894e-01,  5.2870e-01,  1.4635e-01,\n",
      "          1.0030e+00,  4.2070e-01, -3.9510e-02, -1.2440e+00, -9.1030e-01,\n",
      "         -5.1005e-01,  3.1632e+00, -8.1081e-01,  5.8030e-01,  1.1918e+00,\n",
      "          1.0135e+00,  3.1497e-01, -5.1816e-01, -1.0931e+00, -8.6458e-01,\n",
      "          1.1256e-01,  2.1923e+00, -3.0768e-01,  9.0016e-02,  7.2527e-01]])\n",
      "Forward pass\n",
      "Model:  NeuralNet(\n",
      "  (linear1): Linear(in_features=220, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (linear3): Linear(in_features=1000, out_features=200, bias=True)\n",
      "  (linear4): Linear(in_features=200, out_features=1010, bias=True)\n",
      ")\n",
      "Loss:  tensor(1.0639, grad_fn=<MseLossBackward>)\n",
      "0 1.0638850927352905\n",
      "Backward ------ \n",
      "\n",
      "After Optimization ------ \n",
      "\n",
      "Training loop \n",
      "\n",
      "Input  tensor([[-8.0742e-01,  1.2008e+00,  1.0855e-01, -4.2157e-01,  1.6124e+00,\n",
      "         -3.5102e-01,  1.6422e+00,  2.3086e-01, -1.1768e+00, -9.8418e-01,\n",
      "          1.3801e-01, -6.3044e-01,  4.3968e-01,  1.0923e+00,  2.4473e-01,\n",
      "          9.5094e-01, -1.3664e+00, -9.1360e-01,  1.1452e+00, -9.3431e-01,\n",
      "         -9.3493e-01, -1.4570e+00,  9.2529e-01, -7.5493e-01, -5.2806e-01,\n",
      "         -1.8451e+00,  6.2360e-01, -2.3548e+00, -1.2384e+00, -1.5792e+00,\n",
      "         -2.3441e-01,  2.0920e-01,  1.2764e-01, -1.5606e+00, -7.3030e-01,\n",
      "         -1.6016e-01, -1.0527e+00,  9.0262e-01, -7.2090e-01,  1.7800e-01,\n",
      "         -8.2002e-01, -3.1784e-01, -4.5260e-02,  6.9169e-01, -1.1845e+00,\n",
      "          3.4885e-01, -2.6260e+00,  1.4842e+00,  2.4613e+00, -1.4173e-03,\n",
      "          4.0608e-01, -8.1333e-01, -1.2193e-01, -3.6468e-01,  2.7786e+00,\n",
      "          2.9994e-01,  1.1777e+00, -1.0104e+00,  2.0675e-01,  4.4101e-01,\n",
      "          2.8751e+00,  4.2748e-01, -5.7367e-01,  6.9164e-01, -3.7816e-01,\n",
      "         -1.1452e+00, -1.7155e-01, -7.3906e-01, -8.1857e-01, -1.3090e-01,\n",
      "         -7.4715e-01, -1.0838e+00,  8.8823e-01, -1.9291e+00, -1.2603e+00,\n",
      "          7.5107e-01, -1.6132e+00,  7.9421e-01, -9.6048e-01,  1.8557e-01,\n",
      "          5.7217e-01, -2.5630e-01, -1.0373e+00,  9.1366e-01,  1.7175e-01,\n",
      "          6.1340e-01,  1.0816e-01, -1.0130e+00, -2.5380e-01,  1.0955e+00,\n",
      "          5.6980e-01, -6.2561e-01, -1.4423e+00,  4.9491e-01, -1.2016e-01,\n",
      "          4.2932e-01,  2.5774e-01, -3.6188e-01, -1.8866e+00,  2.9298e-01,\n",
      "         -3.2644e-01, -1.2553e+00, -5.6453e-01,  5.5958e-01,  1.6065e-01,\n",
      "         -4.5535e-01, -8.1481e-02,  1.5012e+00, -1.7409e-01, -2.6382e-01,\n",
      "         -7.4317e-01, -7.2446e-01, -1.4672e+00,  6.4123e-01,  9.9994e-01,\n",
      "         -3.3417e-01,  1.6348e-01, -9.4453e-01,  9.9077e-02,  1.5779e+00,\n",
      "         -2.6705e-01, -3.0342e-01,  2.6457e-01, -1.2854e+00,  7.3875e-01,\n",
      "          5.1317e-01,  2.5849e-03,  9.3899e-01, -7.7236e-01,  9.8452e-01,\n",
      "          1.4563e+00, -9.7481e-01, -5.5420e-01, -7.1552e-01,  2.8237e-01,\n",
      "          6.2749e-01,  8.9946e-01, -1.4033e+00,  1.0137e+00,  1.2426e+00,\n",
      "         -6.9546e-01, -4.5240e-01,  2.5272e-01, -1.4671e+00, -1.4358e+00,\n",
      "          4.5576e-01, -2.9694e-01, -4.3443e-02,  6.9445e-01, -2.1604e+00,\n",
      "         -4.9888e-01, -5.2655e-01, -1.8306e-02,  6.5900e-01, -9.5556e-01,\n",
      "          4.3345e-01, -1.2271e+00,  5.4013e-01, -4.9784e-01, -2.9371e-01,\n",
      "          1.8826e-01, -6.1062e-01,  2.1583e+00, -1.3657e+00, -2.1042e-01,\n",
      "         -3.2486e-01,  1.4876e+00, -4.7856e-02,  1.7019e+00, -1.8628e-01,\n",
      "         -7.5126e-01, -4.0946e-01, -7.2211e-01,  3.6262e-01, -3.3697e-01,\n",
      "         -1.7707e-01,  1.2913e+00, -2.0507e+00,  8.8183e-01, -1.0857e+00,\n",
      "          9.0760e-01,  1.0576e-01,  1.8844e+00,  1.7323e+00, -7.0711e-01,\n",
      "         -1.0785e+00, -4.9313e-01,  1.2398e+00, -1.0412e-01, -3.2777e-03,\n",
      "         -6.4322e-01,  4.0814e-02,  4.7032e-01,  1.1604e+00,  1.1637e-01,\n",
      "         -6.2252e-01,  1.5875e+00,  6.4894e-01,  5.2870e-01,  1.4635e-01,\n",
      "          1.0030e+00,  4.2070e-01, -3.9510e-02, -1.2440e+00, -9.1030e-01,\n",
      "         -5.1005e-01,  3.1632e+00, -8.1081e-01,  5.8030e-01,  1.1918e+00,\n",
      "          1.0135e+00,  3.1497e-01, -5.1816e-01, -1.0931e+00, -8.6458e-01,\n",
      "          1.1256e-01,  2.1923e+00, -3.0768e-01,  9.0016e-02,  7.2527e-01]])\n",
      "Forward pass\n",
      "Model:  NeuralNet(\n",
      "  (linear1): Linear(in_features=220, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (linear3): Linear(in_features=1000, out_features=200, bias=True)\n",
      "  (linear4): Linear(in_features=200, out_features=1010, bias=True)\n",
      ")\n",
      "Loss:  tensor(1.0639, grad_fn=<MseLossBackward>)\n",
      "1 1.0638850927352905\n",
      "Backward ------ \n",
      "\n",
      "After Optimization ------ \n",
      "\n",
      "Training loop \n",
      "\n",
      "Input  tensor([[-8.0742e-01,  1.2008e+00,  1.0855e-01, -4.2157e-01,  1.6124e+00,\n",
      "         -3.5102e-01,  1.6422e+00,  2.3086e-01, -1.1768e+00, -9.8418e-01,\n",
      "          1.3801e-01, -6.3044e-01,  4.3968e-01,  1.0923e+00,  2.4473e-01,\n",
      "          9.5094e-01, -1.3664e+00, -9.1360e-01,  1.1452e+00, -9.3431e-01,\n",
      "         -9.3493e-01, -1.4570e+00,  9.2529e-01, -7.5493e-01, -5.2806e-01,\n",
      "         -1.8451e+00,  6.2360e-01, -2.3548e+00, -1.2384e+00, -1.5792e+00,\n",
      "         -2.3441e-01,  2.0920e-01,  1.2764e-01, -1.5606e+00, -7.3030e-01,\n",
      "         -1.6016e-01, -1.0527e+00,  9.0262e-01, -7.2090e-01,  1.7800e-01,\n",
      "         -8.2002e-01, -3.1784e-01, -4.5260e-02,  6.9169e-01, -1.1845e+00,\n",
      "          3.4885e-01, -2.6260e+00,  1.4842e+00,  2.4613e+00, -1.4173e-03,\n",
      "          4.0608e-01, -8.1333e-01, -1.2193e-01, -3.6468e-01,  2.7786e+00,\n",
      "          2.9994e-01,  1.1777e+00, -1.0104e+00,  2.0675e-01,  4.4101e-01,\n",
      "          2.8751e+00,  4.2748e-01, -5.7367e-01,  6.9164e-01, -3.7816e-01,\n",
      "         -1.1452e+00, -1.7155e-01, -7.3906e-01, -8.1857e-01, -1.3090e-01,\n",
      "         -7.4715e-01, -1.0838e+00,  8.8823e-01, -1.9291e+00, -1.2603e+00,\n",
      "          7.5107e-01, -1.6132e+00,  7.9421e-01, -9.6048e-01,  1.8557e-01,\n",
      "          5.7217e-01, -2.5630e-01, -1.0373e+00,  9.1366e-01,  1.7175e-01,\n",
      "          6.1340e-01,  1.0816e-01, -1.0130e+00, -2.5380e-01,  1.0955e+00,\n",
      "          5.6980e-01, -6.2561e-01, -1.4423e+00,  4.9491e-01, -1.2016e-01,\n",
      "          4.2932e-01,  2.5774e-01, -3.6188e-01, -1.8866e+00,  2.9298e-01,\n",
      "         -3.2644e-01, -1.2553e+00, -5.6453e-01,  5.5958e-01,  1.6065e-01,\n",
      "         -4.5535e-01, -8.1481e-02,  1.5012e+00, -1.7409e-01, -2.6382e-01,\n",
      "         -7.4317e-01, -7.2446e-01, -1.4672e+00,  6.4123e-01,  9.9994e-01,\n",
      "         -3.3417e-01,  1.6348e-01, -9.4453e-01,  9.9077e-02,  1.5779e+00,\n",
      "         -2.6705e-01, -3.0342e-01,  2.6457e-01, -1.2854e+00,  7.3875e-01,\n",
      "          5.1317e-01,  2.5849e-03,  9.3899e-01, -7.7236e-01,  9.8452e-01,\n",
      "          1.4563e+00, -9.7481e-01, -5.5420e-01, -7.1552e-01,  2.8237e-01,\n",
      "          6.2749e-01,  8.9946e-01, -1.4033e+00,  1.0137e+00,  1.2426e+00,\n",
      "         -6.9546e-01, -4.5240e-01,  2.5272e-01, -1.4671e+00, -1.4358e+00,\n",
      "          4.5576e-01, -2.9694e-01, -4.3443e-02,  6.9445e-01, -2.1604e+00,\n",
      "         -4.9888e-01, -5.2655e-01, -1.8306e-02,  6.5900e-01, -9.5556e-01,\n",
      "          4.3345e-01, -1.2271e+00,  5.4013e-01, -4.9784e-01, -2.9371e-01,\n",
      "          1.8826e-01, -6.1062e-01,  2.1583e+00, -1.3657e+00, -2.1042e-01,\n",
      "         -3.2486e-01,  1.4876e+00, -4.7856e-02,  1.7019e+00, -1.8628e-01,\n",
      "         -7.5126e-01, -4.0946e-01, -7.2211e-01,  3.6262e-01, -3.3697e-01,\n",
      "         -1.7707e-01,  1.2913e+00, -2.0507e+00,  8.8183e-01, -1.0857e+00,\n",
      "          9.0760e-01,  1.0576e-01,  1.8844e+00,  1.7323e+00, -7.0711e-01,\n",
      "         -1.0785e+00, -4.9313e-01,  1.2398e+00, -1.0412e-01, -3.2777e-03,\n",
      "         -6.4322e-01,  4.0814e-02,  4.7032e-01,  1.1604e+00,  1.1637e-01,\n",
      "         -6.2252e-01,  1.5875e+00,  6.4894e-01,  5.2870e-01,  1.4635e-01,\n",
      "          1.0030e+00,  4.2070e-01, -3.9510e-02, -1.2440e+00, -9.1030e-01,\n",
      "         -5.1005e-01,  3.1632e+00, -8.1081e-01,  5.8030e-01,  1.1918e+00,\n",
      "          1.0135e+00,  3.1497e-01, -5.1816e-01, -1.0931e+00, -8.6458e-01,\n",
      "          1.1256e-01,  2.1923e+00, -3.0768e-01,  9.0016e-02,  7.2527e-01]])\n",
      "Forward pass\n",
      "Model:  NeuralNet(\n",
      "  (linear1): Linear(in_features=220, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (linear3): Linear(in_features=1000, out_features=200, bias=True)\n",
      "  (linear4): Linear(in_features=200, out_features=1010, bias=True)\n",
      ")\n",
      "Loss:  tensor(1.0639, grad_fn=<MseLossBackward>)\n",
      "2 1.0638850927352905\n",
      "Backward ------ \n",
      "\n",
      "After Optimization ------ \n",
      "\n",
      "[1.0638850927352905, 1.0638850927352905, 1.0638850927352905]\n",
      "Predicted ->  tensor([[-0.2321, -0.0130, -0.2268,  ...,  0.0020,  0.1134,  0.1366]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Predicted loss -> tensor(1.0639, grad_fn=<MseLossBackward>)\n",
      "Length:  1010\n",
      "tensor([-0.2321, -0.0130, -0.2268,  ...,  0.0020,  0.1134,  0.1366],\n",
      "       grad_fn=<ViewBackward>)\n",
      "torch.Size([1010])\n",
      "tensor([-0.5160, -1.6859, -0.2202,  ..., -1.7921, -0.9416, -0.5856],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1010])\n",
      "0.49504950495049505\n"
     ]
    }
   ],
   "source": [
    "# loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "losses2 = []\n",
    "\n",
    "H1, H2, H3 = 500, 1000, 200\n",
    "\n",
    "D_in, D_out = 220, 1010\n",
    "\n",
    "model2 = NeuralNet(D_in, H1, H2, H3, D_out)\n",
    "\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# print(x)\n",
    "# print(x.shape)\n",
    "x = torch.reshape(x_tensor_normalized,(1,220))\n",
    "print(x)\n",
    "print(x.shape)\n",
    "y = torch.reshape(y, (1,1010))\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "# print(y.shape)\n",
    "\n",
    "for t in range(3):\n",
    "       print(\"Training loop \\n\")\n",
    "       print(\"Input \",x.float())\n",
    "       y_pred=model2(x.float())\n",
    "#        print(\"Input shape: \",x.shape)\n",
    "#        print(\"Predicted: \",y_pred)\n",
    "#        print(\"Predicted shape: \",y_pred.shape)\n",
    "#        print(\"Ground truth: \", y_data.float())\n",
    "#        print(\"Ground truth shape: \", y_data.reshape(1,1010).shape)\n",
    "\n",
    "       print(\"Model: \", model2)\n",
    "#        print(\"Model: \", model2.linear1.weight.grad)\n",
    "#        print(\"Model: \", model2.linear2.weight.grad)\n",
    "#        print(\"Model: \", model2.linear3.weight.grad)\n",
    "#        print(\"Model: \", model2.linear4.weight.grad)\n",
    "       loss = loss_fn(y_pred, y_data.reshape(1,1010).float())\n",
    "       print(\"Loss: \",loss)\n",
    "       print(t, loss.item())\n",
    "       losses2.append(loss.item())\n",
    "#        print(\"Gradient: \", loss.grad)\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       print(\"Backward ------ \\n\")\n",
    "#        print(\"Model: \", model2.linear1.weight.grad)\n",
    "#        print(\"Model: \", model2.linear2.weight.grad)\n",
    "#        print(\"Model: \", model2.linear3.weight.grad)\n",
    "#        print(\"Model: \", model2.linear4.weight.grad)       print(\"Gradient: \", loss.grad)\n",
    "#        optimizer.step()\n",
    "       print(\"After Optimization ------ \\n\")\n",
    "#        print(\"Model: \", model2.linear1.weight.grad)\n",
    "#        print(\"Model: \", model2.linear2.weight.grad)\n",
    "#        print(\"Model: \", model2.linear3.weight.grad)\n",
    "#        print(\"Model: \", model2.linear4.weight.grad)\n",
    "\n",
    "\n",
    "print(losses2)\n",
    "print(\"Predicted -> \",y_pred)\n",
    "loss_fn_test = torch.nn.MSELoss()\n",
    "print(\"Predicted loss ->\", loss_fn_test(y_pred.reshape(1010,1), y_data.reshape(1010,1).float()))\n",
    "# Make the forward pass and then find accuracy of predictions. Alternative: Pass model to below function\n",
    "get_accuracy(model2, y_pred.reshape(1010,1), y_data.reshape(1010,1), 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss  --> \n",
      " tensor(1.0579)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean loss  --> \\n\", torch.mean(torch.Tensor(losses2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = NeuralNet(D_in, H1, H2, H3, D_out)\n",
    "optimizer = torch.optim.SGD(model3.parameters(), lr=1e-4*2)\n",
    "losses3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-36d5d95b1a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m        \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mlosses3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5d0d3fe4174e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "       y_pred = model3(x_data)\n",
    "       loss=loss_fn(y_pred, y_data)\n",
    "       print(t, loss.item())\n",
    "       losses3.append(loss.item())\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss  --> \n",
      " tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean loss  --> \\n\", torch.mean(torch.Tensor(losses3)))\n",
    "#%%\n",
    "model4 = NeuralNet(D_in, H1, H2, H3, D_out)\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=1e-4*2)\n",
    "losses4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7ce07a12fa91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m        \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mlosses4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5d0d3fe4174e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "       y_pred = model4(x_data)\n",
    "       loss = loss_fn(y_pred, y_data)\n",
    "       print(t, loss.item())\n",
    "       losses4.append(loss.item())\n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss  --> \n",
      " tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean loss  --> \\n\", torch.mean(torch.Tensor(losses4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%<br>\n",
    "%%<br>\n",
    "Save the model that has the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4.state_dict(), './fcn_trained.dat')\n",
    "# Load the trained parameters\n",
    "model2.load_state_dict(torch.load('./fcn_trained.dat'))\n",
    "# Set the model to evaluation mode\n",
    "model2.eval()\n",
    "#%%\n",
    "def predict(input_values):\n",
    "       with torch.no_grad():\n",
    "              output = model2(input_values)\n",
    "       return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = torch.Tensor(X_test.dropna().to_numpy())\n",
    "# Apple yield of Australia for 2017\n",
    "print(\"Apple yield for 2017 \\n \", Australia_yield_2017_apples[\"Y2017\"])\n",
    "y_eval = torch.mean(torch.Tensor(Australia_yield_2017_apples[\"Y2017\"].to_numpy()))\n",
    "y_eval = y_eval/1000000\n",
    "#%%\n",
    "# Normalize\n",
    "x_eval_data = (x_eval-x_eval.mean())/(x_eval.max()-x_eval.min())\n",
    "x_eval_data = torch.reshape(x_eval_data,(12,1))\n",
    "# %%\n",
    "y_eval_pred = predict(x_eval_data)\n",
    "# y_eval = torch.reshape(y_eval, (12,1))\n",
    "print(\"ACTUAL    \",y_eval)\n",
    "print(\"PREDICTED   \",torch.mean(y_eval_pred))\n",
    "# %%\n",
    "# RMSE\n",
    "prediction_loss = np.sqrt(mean_squared_error(y_eval, torch.mean(y_eval_pred)))\n",
    "print(\"Prediction loss --> \", prediction_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}